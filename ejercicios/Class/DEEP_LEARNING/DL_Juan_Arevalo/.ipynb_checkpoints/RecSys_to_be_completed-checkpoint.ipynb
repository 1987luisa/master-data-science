{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender systems\n",
    "\n",
    "## One of the most common uses of big data is to predict and suggest what users may want.  This allows Google to show you relevant ads or to suggest news in Google Now; Amazon to recommend relevant products; Netflix to recommend movies that you might like; or most recently, the famous **Weekly Dicovery** of Spotify.\n",
    "\n",
    "## All these products are based on systems of recommendation: a information retrieval method to provide users with relevant, yet novel and diverse, information. \n",
    "\n",
    "## In this class we will use a pretty famous dataset based on movies ratings, 'MovieLens', to learn the basics of recommender systems. \n",
    "\n",
    "## Table of Contents (times are approximated)\n",
    "\n",
    "1. [Getting and analysing some data (~1:30 h)](#data)\n",
    "2. [Most popular movies (~30 min)](#popular)\n",
    "3. [Metrics for recommender systems (~1.30h)](#metrics)\n",
    "4. [Collaborative Filtering (~15 min)](#cf)  \n",
    "   4.1 [Co-occurrence Matrix (~1.30h)](#copurchase)\n",
    "   <br></br>\n",
    "   4.2 [Memory-based CF (~1 h)](#memory-base)\n",
    "   <br></br>\n",
    "   4.3 [Model-based CF (~2 h)](#model-base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "## 1.1 Load data\n",
    "\n",
    "We will use MovieLens dataset, which is one of the most common datasets used when implementing and testing recommender engines. This data set consists of:\n",
    "* 100,000 ratings (1-5) from 943 users on 1682 movies. \n",
    "* Each user has rated at least 20 movies. \n",
    "* Simple demographic info for the users (age, gender, occupation, zip)\n",
    "\n",
    "The data was collected through the MovieLens [website](https://movielens.org) during the seven-month period from September 19th, \n",
    "1997 through April 22nd, 1998. This data has been cleaned up - users\n",
    "who had less than 20 ratings or did not have complete demographic\n",
    "information were removed from this data set.\n",
    "\n",
    "You can download the dataset [here](http://files.grouplens.org/datasets/movielens/ml-100k.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the readme file!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"./data/ml-100k/\"\n",
    "readme = os.path.join(data_root, \"README\")\n",
    "#!cat $readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "datafile = os.path.join(data_root, \"u.data\")\n",
    "data = pd.read_csv(datafile, sep='\\t', names=columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 943 users and 1682 items\n"
     ]
    }
   ],
   "source": [
    "n_users = data.user_id.unique().shape[0]\n",
    "n_items = data.item_id.unique().shape[0]\n",
    "print(\"There are %s users and %s items\" %(n_users, n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 1, ..., 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.values[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 A dictionary for movies and a search tool\n",
    "\n",
    "In order to analyze the predicted recommendations, let's create a python dictonary that will allow us to translate any item id to the corresponding movie title. Also, let's write a small function that returns the ids of the movies containing some text.\n",
    "\n",
    "The correspondance between titles and ids is stored in the u.item file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"./data/ml-100k/\"\n",
    "items_id_file = os.path.join(data_root, \"u.item\")\n",
    "#!head $items_id_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 196 viewed 'b'Kolya (1996)'' and gave a 3 rating\n",
      "User 186 viewed 'b'L.A. Confidential (1997)'' and gave a 3 rating\n",
      "User 22 viewed 'b'Heavyweights (1994)'' and gave a 1 rating\n",
      "User 244 viewed 'b'Legends of the Fall (1994)'' and gave a 2 rating\n",
      "User 166 viewed 'b'Jackie Brown (1997)'' and gave a 1 rating\n",
      "User 298 viewed 'b'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)'' and gave a 4 rating\n",
      "User 115 viewed 'b'Hunt for Red October, The (1990)'' and gave a 2 rating\n",
      "User 253 viewed 'b'Jungle Book, The (1994)'' and gave a 5 rating\n",
      "User 305 viewed 'b'Grease (1978)'' and gave a 3 rating\n",
      "User 6 viewed 'b'Remains of the Day, The (1993)'' and gave a 3 rating\n",
      "User 62 viewed 'b'Men in Black (1997)'' and gave a 2 rating\n",
      "User 286 viewed 'b\"Romy and Michele's High School Reunion (1997)\"' and gave a 5 rating\n",
      "User 200 viewed 'b'Star Trek: First Contact (1996)'' and gave a 5 rating\n",
      "User 210 viewed 'b'To Wong Foo, Thanks for Everything! Julie Newmar (1995)'' and gave a 3 rating\n",
      "User 224 viewed 'b'Batman Forever (1995)'' and gave a 3 rating\n",
      "User 303 viewed 'b'Only You (1994)'' and gave a 3 rating\n",
      "User 122 viewed 'b'Age of Innocence, The (1993)'' and gave a 5 rating\n",
      "User 194 viewed 'b'Sabrina (1995)'' and gave a 2 rating\n",
      "User 291 viewed 'b'Just Cause (1995)'' and gave a 4 rating\n",
      "User 234 viewed 'b'Endless Summer 2, The (1994)'' and gave a 2 rating\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary for movie titles and ids\n",
    "item_dict = {}\n",
    "with io.open(items_id_file, 'rb') as f:\n",
    "    for line in f.readlines():\n",
    "        record = line.split(b'|')\n",
    "        item_dict[int(record[0])] = str(record[1])\n",
    "    \n",
    "# We can use this dict to see the films a user has seen, for instance. \n",
    "for record in data.values[:20]:\n",
    "    print(\"User {u} viewed '{m}' and gave a {r} rating\".format(u=record[0], m=item_dict[record[1]], r=record[2]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that retrieves all the ids and titles for movies containing 'text' in its title\n",
    "def returnItemId(text, ids):\n",
    "    \"\"\"\n",
    "    :param text: string to be looked for in movies titles\n",
    "    :param ids: dicttionary of {id:title}\n",
    "    \n",
    "    :return: a list of (id,title) if text found in titles, and an empty list otherwise.\n",
    "    \"\"\"\n",
    "    search = [(k, v.lower().find(text.lower())) \n",
    "              for k,v in list(ids.items())]\n",
    "    index = [k for k,v in search if v>-1]\n",
    "    \n",
    "    return list(zip(index, [ids[i] for i in index]) if len(index)>0 else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(240, \"b'Beavis and Butt-head Do America (1996)'\"),\n",
       " (435, \"b'Butch Cassidy and the Sundance Kid (1969)'\"),\n",
       " (580,\n",
       "  \"b'Englishman Who Went Up a Hill, But Came Down a Mountain, The (1995)'\"),\n",
       " (1401, \"b'M. Butterfly (1993)'\"),\n",
       " (1459, \"b'Madame Butterfly (1995)'\"),\n",
       " (1614, \"b'Reluctant Debutante, The (1958)'\"),\n",
       " (1621, \"b'Butterfly Kiss (1995)'\"),\n",
       " (1645, \"b'Butcher Boy, The (1998)'\"),\n",
       " (1650, \"b'Butcher Boy, The (1998)'\")]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returnItemId('but', item_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data consistency (always double check everything!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-22-14542bd19b5a>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-22-14542bd19b5a>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    #    RELLENAR\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# print a couple of duplicated titles\n",
    "with io.open(items_id_file, 'rb') as f:\n",
    "    <fill in>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n",
      "1664\n"
     ]
    }
   ],
   "source": [
    "# check whether titles are unique or not\n",
    "print(len(set(item_dict.keys())))\n",
    "print(len(set(item_dict.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One work around: create another dict that consolidates ids with the same movie title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"b'Toy Story (1995)'\",\n",
       " \"b'GoldenEye (1995)'\",\n",
       " \"b'Four Rooms (1995)'\",\n",
       " \"b'Get Shorty (1995)'\",\n",
       " \"b'Copycat (1995)'\",\n",
       " \"b'Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)'\",\n",
       " \"b'Twelve Monkeys (1995)'\",\n",
       " \"b'Babe (1995)'\",\n",
       " \"b'Dead Man Walking (1995)'\",\n",
       " \"b'Richard III (1995)'\",\n",
       " \"b'Seven (Se7en) (1995)'\",\n",
       " \"b'Usual Suspects, The (1995)'\",\n",
       " \"b'Mighty Aphrodite (1995)'\",\n",
       " \"b'Postino, Il (1994)'\",\n",
       " 'b\"Mr. Holland\\'s Opus (1995)\"',\n",
       " \"b'French Twist (Gazon maudit) (1995)'\",\n",
       " \"b'From Dusk Till Dawn (1996)'\",\n",
       " \"b'White Balloon, The (1995)'\",\n",
       " 'b\"Antonia\\'s Line (1995)\"',\n",
       " \"b'Angels and Insects (1995)'\",\n",
       " \"b'Muppet Treasure Island (1996)'\",\n",
       " \"b'Braveheart (1995)'\",\n",
       " \"b'Taxi Driver (1976)'\",\n",
       " \"b'Rumble in the Bronx (1995)'\",\n",
       " \"b'Birdcage, The (1996)'\",\n",
       " \"b'Brothers McMullen, The (1995)'\",\n",
       " \"b'Bad Boys (1995)'\",\n",
       " \"b'Apollo 13 (1995)'\",\n",
       " \"b'Batman Forever (1995)'\",\n",
       " \"b'Belle de jour (1967)'\",\n",
       " \"b'Crimson Tide (1995)'\",\n",
       " \"b'Crumb (1994)'\",\n",
       " \"b'Desperado (1995)'\",\n",
       " \"b'Doom Generation, The (1995)'\",\n",
       " \"b'Free Willy 2: The Adventure Home (1995)'\",\n",
       " \"b'Mad Love (1995)'\",\n",
       " \"b'Nadja (1994)'\",\n",
       " \"b'Net, The (1995)'\",\n",
       " \"b'Strange Days (1995)'\",\n",
       " \"b'To Wong Foo, Thanks for Everything! Julie Newmar (1995)'\",\n",
       " \"b'Billy Madison (1995)'\",\n",
       " \"b'Clerks (1994)'\",\n",
       " \"b'Disclosure (1994)'\",\n",
       " \"b'Dolores Claiborne (1994)'\",\n",
       " \"b'Eat Drink Man Woman (1994)'\",\n",
       " \"b'Exotica (1994)'\",\n",
       " \"b'Ed Wood (1994)'\",\n",
       " \"b'Hoop Dreams (1994)'\",\n",
       " \"b'I.Q. (1994)'\",\n",
       " \"b'Star Wars (1977)'\",\n",
       " \"b'Legends of the Fall (1994)'\",\n",
       " \"b'Madness of King George, The (1994)'\",\n",
       " \"b'Natural Born Killers (1994)'\",\n",
       " \"b'Outbreak (1995)'\",\n",
       " \"b'Professional, The (1994)'\",\n",
       " \"b'Pulp Fiction (1994)'\",\n",
       " \"b'Priest (1994)'\",\n",
       " \"b'Quiz Show (1994)'\",\n",
       " \"b'Three Colors: Red (1994)'\",\n",
       " \"b'Three Colors: Blue (1993)'\",\n",
       " \"b'Three Colors: White (1994)'\",\n",
       " \"b'Stargate (1994)'\",\n",
       " \"b'Santa Clause, The (1994)'\",\n",
       " \"b'Shawshank Redemption, The (1994)'\",\n",
       " 'b\"What\\'s Eating Gilbert Grape (1993)\"',\n",
       " \"b'While You Were Sleeping (1995)'\",\n",
       " \"b'Ace Ventura: Pet Detective (1994)'\",\n",
       " \"b'Crow, The (1994)'\",\n",
       " \"b'Forrest Gump (1994)'\",\n",
       " \"b'Four Weddings and a Funeral (1994)'\",\n",
       " \"b'Lion King, The (1994)'\",\n",
       " \"b'Mask, The (1994)'\",\n",
       " \"b'Maverick (1994)'\",\n",
       " \"b'Faster Pussycat! Kill! Kill! (1965)'\",\n",
       " \"b'Brother Minister: The Assassination of Malcolm X (1994)'\",\n",
       " 'b\"Carlito\\'s Way (1993)\"',\n",
       " \"b'Firm, The (1993)'\",\n",
       " \"b'Free Willy (1993)'\",\n",
       " \"b'Fugitive, The (1993)'\",\n",
       " \"b'Hot Shots! Part Deux (1993)'\",\n",
       " \"b'Hudsucker Proxy, The (1994)'\",\n",
       " \"b'Jurassic Park (1993)'\",\n",
       " \"b'Much Ado About Nothing (1993)'\",\n",
       " 'b\"Robert A. Heinlein\\'s The Puppet Masters (1994)\"',\n",
       " \"b'Ref, The (1994)'\",\n",
       " \"b'Remains of the Day, The (1993)'\",\n",
       " \"b'Searching for Bobby Fischer (1993)'\",\n",
       " \"b'Sleepless in Seattle (1993)'\",\n",
       " \"b'Blade Runner (1982)'\",\n",
       " \"b'So I Married an Axe Murderer (1993)'\",\n",
       " \"b'Nightmare Before Christmas, The (1993)'\",\n",
       " \"b'True Romance (1993)'\",\n",
       " \"b'Welcome to the Dollhouse (1995)'\",\n",
       " \"b'Home Alone (1990)'\",\n",
       " \"b'Aladdin (1992)'\",\n",
       " \"b'Terminator 2: Judgment Day (1991)'\",\n",
       " \"b'Dances with Wolves (1990)'\",\n",
       " \"b'Silence of the Lambs, The (1991)'\",\n",
       " \"b'Snow White and the Seven Dwarfs (1937)'\",\n",
       " \"b'Fargo (1996)'\",\n",
       " \"b'Heavy Metal (1981)'\",\n",
       " \"b'Aristocats, The (1970)'\",\n",
       " \"b'All Dogs Go to Heaven 2 (1996)'\",\n",
       " \"b'Theodore Rex (1995)'\",\n",
       " \"b'Sgt. Bilko (1996)'\",\n",
       " \"b'Diabolique (1996)'\",\n",
       " \"b'Moll Flanders (1996)'\",\n",
       " \"b'Kids in the Hall: Brain Candy (1996)'\",\n",
       " \"b'Mystery Science Theater 3000: The Movie (1996)'\",\n",
       " \"b'Operation Dumbo Drop (1995)'\",\n",
       " \"b'Truth About Cats & Dogs, The (1996)'\",\n",
       " \"b'Flipper (1996)'\",\n",
       " \"b'Horseman on the Roof, The (Hussard sur le toit, Le) (1995)'\",\n",
       " \"b'Wallace & Gromit: The Best of Aardman Animation (1996)'\",\n",
       " \"b'Haunted World of Edward D. Wood Jr., The (1995)'\",\n",
       " \"b'Cold Comfort Farm (1995)'\",\n",
       " \"b'Rock, The (1996)'\",\n",
       " \"b'Twister (1996)'\",\n",
       " \"b'Maya Lin: A Strong Clear Vision (1994)'\",\n",
       " \"b'Striptease (1996)'\",\n",
       " \"b'Independence Day (ID4) (1996)'\",\n",
       " \"b'Cable Guy, The (1996)'\",\n",
       " \"b'Frighteners, The (1996)'\",\n",
       " \"b'Lone Star (1996)'\",\n",
       " \"b'Phenomenon (1996)'\",\n",
       " \"b'Spitfire Grill, The (1996)'\",\n",
       " \"b'Godfather, The (1972)'\",\n",
       " \"b'Supercop (1992)'\",\n",
       " \"b'Bound (1996)'\",\n",
       " \"b'Kansas City (1996)'\",\n",
       " 'b\"Breakfast at Tiffany\\'s (1961)\"',\n",
       " \"b'Wizard of Oz, The (1939)'\",\n",
       " \"b'Gone with the Wind (1939)'\",\n",
       " \"b'Citizen Kane (1941)'\",\n",
       " \"b'2001: A Space Odyssey (1968)'\",\n",
       " \"b'Mr. Smith Goes to Washington (1939)'\",\n",
       " \"b'Big Night (1996)'\",\n",
       " \"b'D3: The Mighty Ducks (1996)'\",\n",
       " \"b'Love Bug, The (1969)'\",\n",
       " \"b'Homeward Bound: The Incredible Journey (1993)'\",\n",
       " \"b'20,000 Leagues Under the Sea (1954)'\",\n",
       " \"b'Bedknobs and Broomsticks (1971)'\",\n",
       " \"b'Sound of Music, The (1965)'\",\n",
       " \"b'Die Hard (1988)'\",\n",
       " \"b'Lawnmower Man, The (1992)'\",\n",
       " \"b'Unhook the Stars (1996)'\",\n",
       " \"b'Long Kiss Goodnight, The (1996)'\",\n",
       " \"b'Ghost and the Darkness, The (1996)'\",\n",
       " \"b'Jude (1996)'\",\n",
       " \"b'Swingers (1996)'\",\n",
       " \"b'Willy Wonka and the Chocolate Factory (1971)'\",\n",
       " \"b'Sleeper (1973)'\",\n",
       " \"b'Fish Called Wanda, A (1988)'\",\n",
       " 'b\"Monty Python\\'s Life of Brian (1979)\"',\n",
       " \"b'Dirty Dancing (1987)'\",\n",
       " \"b'Reservoir Dogs (1992)'\",\n",
       " \"b'Platoon (1986)'\",\n",
       " 'b\"Weekend at Bernie\\'s (1989)\"',\n",
       " \"b'Basic Instinct (1992)'\",\n",
       " \"b'Glengarry Glen Ross (1992)'\",\n",
       " \"b'Top Gun (1986)'\",\n",
       " \"b'On Golden Pond (1981)'\",\n",
       " \"b'Return of the Pink Panther, The (1974)'\",\n",
       " \"b'Abyss, The (1989)'\",\n",
       " \"b'Jean de Florette (1986)'\",\n",
       " \"b'Manon of the Spring (Manon des sources) (1986)'\",\n",
       " \"b'Private Benjamin (1980)'\",\n",
       " \"b'Monty Python and the Holy Grail (1974)'\",\n",
       " \"b'Wrong Trousers, The (1993)'\",\n",
       " \"b'Cinema Paradiso (1988)'\",\n",
       " \"b'Delicatessen (1991)'\",\n",
       " \"b'Empire Strikes Back, The (1980)'\",\n",
       " \"b'Princess Bride, The (1987)'\",\n",
       " \"b'Raiders of the Lost Ark (1981)'\",\n",
       " \"b'Brazil (1985)'\",\n",
       " \"b'Aliens (1986)'\",\n",
       " \"b'Good, The Bad and The Ugly, The (1966)'\",\n",
       " \"b'12 Angry Men (1957)'\",\n",
       " \"b'Clockwork Orange, A (1971)'\",\n",
       " \"b'Apocalypse Now (1979)'\",\n",
       " \"b'Return of the Jedi (1983)'\",\n",
       " \"b'GoodFellas (1990)'\",\n",
       " \"b'Alien (1979)'\",\n",
       " \"b'Army of Darkness (1993)'\",\n",
       " \"b'Psycho (1960)'\",\n",
       " \"b'Blues Brothers, The (1980)'\",\n",
       " \"b'Godfather: Part II, The (1974)'\",\n",
       " \"b'Full Metal Jacket (1987)'\",\n",
       " \"b'Grand Day Out, A (1992)'\",\n",
       " \"b'Henry V (1989)'\",\n",
       " \"b'Amadeus (1984)'\",\n",
       " \"b'Raging Bull (1980)'\",\n",
       " \"b'Right Stuff, The (1983)'\",\n",
       " \"b'Sting, The (1973)'\",\n",
       " \"b'Terminator, The (1984)'\",\n",
       " \"b'Dead Poets Society (1989)'\",\n",
       " \"b'Graduate, The (1967)'\",\n",
       " \"b'Nikita (La Femme Nikita) (1990)'\",\n",
       " \"b'Bridge on the River Kwai, The (1957)'\",\n",
       " \"b'Shining, The (1980)'\",\n",
       " \"b'Evil Dead II (1987)'\",\n",
       " \"b'Groundhog Day (1993)'\",\n",
       " \"b'Unforgiven (1992)'\",\n",
       " \"b'Back to the Future (1985)'\",\n",
       " \"b'Patton (1970)'\",\n",
       " \"b'Akira (1988)'\",\n",
       " \"b'Cyrano de Bergerac (1990)'\",\n",
       " \"b'Young Frankenstein (1974)'\",\n",
       " \"b'This Is Spinal Tap (1984)'\",\n",
       " \"b'Indiana Jones and the Last Crusade (1989)'\",\n",
       " \"b'M*A*S*H (1970)'\",\n",
       " \"b'Unbearable Lightness of Being, The (1988)'\",\n",
       " \"b'Room with a View, A (1986)'\",\n",
       " \"b'Pink Floyd - The Wall (1982)'\",\n",
       " \"b'Field of Dreams (1989)'\",\n",
       " \"b'When Harry Met Sally... (1989)'\",\n",
       " 'b\"Bram Stoker\\'s Dracula (1992)\"',\n",
       " \"b'Cape Fear (1991)'\",\n",
       " \"b'Nightmare on Elm Street, A (1984)'\",\n",
       " \"b'Mirror Has Two Faces, The (1996)'\",\n",
       " \"b'Breaking the Waves (1996)'\",\n",
       " \"b'Star Trek: First Contact (1996)'\",\n",
       " \"b'Sling Blade (1996)'\",\n",
       " \"b'Ridicule (1996)'\",\n",
       " \"b'101 Dalmatians (1996)'\",\n",
       " \"b'Die Hard 2 (1990)'\",\n",
       " \"b'Star Trek VI: The Undiscovered Country (1991)'\",\n",
       " \"b'Star Trek: The Wrath of Khan (1982)'\",\n",
       " \"b'Star Trek III: The Search for Spock (1984)'\",\n",
       " \"b'Star Trek IV: The Voyage Home (1986)'\",\n",
       " \"b'Batman Returns (1992)'\",\n",
       " \"b'Young Guns (1988)'\",\n",
       " \"b'Under Siege (1992)'\",\n",
       " \"b'Jaws (1975)'\",\n",
       " \"b'Mars Attacks! (1996)'\",\n",
       " \"b'Citizen Ruth (1996)'\",\n",
       " \"b'Jerry Maguire (1996)'\",\n",
       " \"b'Raising Arizona (1987)'\",\n",
       " \"b'Sneakers (1992)'\",\n",
       " \"b'Beavis and Butt-head Do America (1996)'\",\n",
       " \"b'Last of the Mohicans, The (1992)'\",\n",
       " \"b'Kolya (1996)'\",\n",
       " \"b'Jungle2Jungle (1997)'\",\n",
       " 'b\"Smilla\\'s Sense of Snow (1997)\"',\n",
       " 'b\"Devil\\'s Own, The (1997)\"',\n",
       " \"b'Chasing Amy (1997)'\",\n",
       " \"b'Turbo: A Power Rangers Movie (1997)'\",\n",
       " \"b'Grosse Pointe Blank (1997)'\",\n",
       " \"b'Austin Powers: International Man of Mystery (1997)'\",\n",
       " \"b'Fifth Element, The (1997)'\",\n",
       " \"b'Shall We Dance? (1996)'\",\n",
       " \"b'Lost World: Jurassic Park, The (1997)'\",\n",
       " \"b'Pillow Book, The (1995)'\",\n",
       " \"b'Batman & Robin (1997)'\",\n",
       " 'b\"My Best Friend\\'s Wedding (1997)\"',\n",
       " \"b'When the Cats Away (Chacun cherche son chat) (1996)'\",\n",
       " \"b'Men in Black (1997)'\",\n",
       " \"b'Contact (1997)'\",\n",
       " \"b'George of the Jungle (1997)'\",\n",
       " \"b'Event Horizon (1997)'\",\n",
       " \"b'Air Bud (1997)'\",\n",
       " \"b'In the Company of Men (1997)'\",\n",
       " \"b'Steel (1997)'\",\n",
       " \"b'Mimic (1997)'\",\n",
       " \"b'Hunt for Red October, The (1990)'\",\n",
       " \"b'Kull the Conqueror (1997)'\",\n",
       " \"b'unknown'\",\n",
       " \"b'Chasing Amy (1997)'\",\n",
       " \"b'Full Monty, The (1997)'\",\n",
       " \"b'Gattaca (1997)'\",\n",
       " \"b'Starship Troopers (1997)'\",\n",
       " \"b'Good Will Hunting (1997)'\",\n",
       " \"b'Heat (1995)'\",\n",
       " \"b'Sabrina (1995)'\",\n",
       " \"b'Sense and Sensibility (1995)'\",\n",
       " \"b'Leaving Las Vegas (1995)'\",\n",
       " \"b'Restoration (1995)'\",\n",
       " \"b'Bed of Roses (1996)'\",\n",
       " \"b'Once Upon a Time... When We Were Colored (1995)'\",\n",
       " \"b'Up Close and Personal (1996)'\",\n",
       " \"b'River Wild, The (1994)'\",\n",
       " \"b'Time to Kill, A (1996)'\",\n",
       " \"b'Emma (1996)'\",\n",
       " \"b'Tin Cup (1996)'\",\n",
       " \"b'Secrets & Lies (1996)'\",\n",
       " \"b'English Patient, The (1996)'\",\n",
       " 'b\"Marvin\\'s Room (1996)\"',\n",
       " \"b'Scream (1996)'\",\n",
       " \"b'Evita (1996)'\",\n",
       " \"b'Fierce Creatures (1997)'\",\n",
       " \"b'Absolute Power (1997)'\",\n",
       " \"b'Rosewood (1997)'\",\n",
       " \"b'Donnie Brasco (1997)'\",\n",
       " \"b'Liar Liar (1997)'\",\n",
       " \"b'Breakdown (1997)'\",\n",
       " \"b'Promesse, La (1996)'\",\n",
       " 'b\"Ulee\\'s Gold (1997)\"',\n",
       " \"b'Face/Off (1997)'\",\n",
       " \"b'Hoodlum (1997)'\",\n",
       " \"b'Air Force One (1997)'\",\n",
       " \"b'In & Out (1997)'\",\n",
       " \"b'L.A. Confidential (1997)'\",\n",
       " 'b\"Ulee\\'s Gold (1997)\"',\n",
       " \"b'Fly Away Home (1996)'\",\n",
       " \"b'Ice Storm, The (1997)'\",\n",
       " \"b'Mrs. Brown (Her Majesty, Mrs. Brown) (1997)'\",\n",
       " 'b\"Devil\\'s Advocate, The (1997)\"',\n",
       " \"b'FairyTale: A True Story (1997)'\",\n",
       " \"b'Deceiver (1997)'\",\n",
       " \"b'Rainmaker, The (1997)'\",\n",
       " \"b'Wings of the Dove, The (1997)'\",\n",
       " \"b'Midnight in the Garden of Good and Evil (1997)'\",\n",
       " \"b'Titanic (1997)'\",\n",
       " \"b'3 Ninjas: High Noon At Mega Mountain (1998)'\",\n",
       " \"b'Apt Pupil (1998)'\",\n",
       " \"b'As Good As It Gets (1997)'\",\n",
       " \"b'In the Name of the Father (1993)'\",\n",
       " 'b\"Schindler\\'s List (1993)\"',\n",
       " \"b'Everyone Says I Love You (1996)'\",\n",
       " \"b'Paradise Lost: The Child Murders at Robin Hood Hills (1996)'\",\n",
       " \"b'Mother (1996)'\",\n",
       " \"b'Murder at 1600 (1997)'\",\n",
       " 'b\"Dante\\'s Peak (1997)\"',\n",
       " \"b'Lost Highway (1997)'\",\n",
       " \"b'Crash (1996)'\",\n",
       " \"b'G.I. Jane (1997)'\",\n",
       " \"b'Cop Land (1997)'\",\n",
       " \"b'Conspiracy Theory (1997)'\",\n",
       " \"b'Desperate Measures (1998)'\",\n",
       " \"b'187 (1997)'\",\n",
       " \"b'Edge, The (1997)'\",\n",
       " \"b'Kiss the Girls (1997)'\",\n",
       " \"b'Game, The (1997)'\",\n",
       " \"b'U Turn (1997)'\",\n",
       " \"b'How to Be a Player (1997)'\",\n",
       " \"b'Playing God (1997)'\",\n",
       " \"b'House of Yes, The (1997)'\",\n",
       " \"b'Bean (1997)'\",\n",
       " \"b'Mad City (1997)'\",\n",
       " \"b'Boogie Nights (1997)'\",\n",
       " \"b'Critical Care (1997)'\",\n",
       " \"b'Man Who Knew Too Little, The (1997)'\",\n",
       " \"b'Alien: Resurrection (1997)'\",\n",
       " \"b'Apostle, The (1997)'\",\n",
       " \"b'Deconstructing Harry (1997)'\",\n",
       " \"b'Jackie Brown (1997)'\",\n",
       " \"b'Wag the Dog (1997)'\",\n",
       " \"b'Desperate Measures (1998)'\",\n",
       " \"b'Hard Rain (1998)'\",\n",
       " \"b'Fallen (1998)'\",\n",
       " \"b'Prophecy II, The (1998)'\",\n",
       " \"b'Spice World (1997)'\",\n",
       " \"b'Deep Rising (1998)'\",\n",
       " \"b'Wedding Singer, The (1998)'\",\n",
       " \"b'Sphere (1998)'\",\n",
       " \"b'Client, The (1994)'\",\n",
       " 'b\"One Flew Over the Cuckoo\\'s Nest (1975)\"',\n",
       " \"b'Spawn (1997)'\",\n",
       " \"b'Assignment, The (1997)'\",\n",
       " \"b'Wonderland (1997)'\",\n",
       " \"b'Incognito (1997)'\",\n",
       " \"b'Blues Brothers 2000 (1998)'\",\n",
       " \"b'Sudden Death (1995)'\",\n",
       " \"b'Ace Ventura: When Nature Calls (1995)'\",\n",
       " \"b'Powder (1995)'\",\n",
       " \"b'Dangerous Minds (1995)'\",\n",
       " \"b'Clueless (1995)'\",\n",
       " \"b'Bio-Dome (1996)'\",\n",
       " \"b'Black Sheep (1996)'\",\n",
       " \"b'Mary Reilly (1996)'\",\n",
       " \"b'Bridges of Madison County, The (1995)'\",\n",
       " \"b'Jeffrey (1995)'\",\n",
       " \"b'Judge Dredd (1995)'\",\n",
       " \"b'Mighty Morphin Power Rangers: The Movie (1995)'\",\n",
       " \"b'Showgirls (1995)'\",\n",
       " \"b'Houseguest (1994)'\",\n",
       " \"b'Heavyweights (1994)'\",\n",
       " \"b'Miracle on 34th Street (1994)'\",\n",
       " \"b'Tales From the Crypt Presents: Demon Knight (1995)'\",\n",
       " \"b'Star Trek: Generations (1994)'\",\n",
       " 'b\"Muriel\\'s Wedding (1994)\"',\n",
       " \"b'Adventures of Priscilla, Queen of the Desert, The (1994)'\",\n",
       " \"b'Flintstones, The (1994)'\",\n",
       " \"b'Naked Gun 33 1/3: The Final Insult (1994)'\",\n",
       " \"b'True Lies (1994)'\",\n",
       " \"b'Addams Family Values (1993)'\",\n",
       " \"b'Age of Innocence, The (1993)'\",\n",
       " \"b'Beverly Hills Cop III (1994)'\",\n",
       " \"b'Black Beauty (1994)'\",\n",
       " \"b'Fear of a Black Hat (1993)'\",\n",
       " \"b'Last Action Hero (1993)'\",\n",
       " \"b'Man Without a Face, The (1993)'\",\n",
       " \"b'Mrs. Doubtfire (1993)'\",\n",
       " \"b'Radioland Murders (1994)'\",\n",
       " \"b'Robin Hood: Men in Tights (1993)'\",\n",
       " \"b'Serial Mom (1994)'\",\n",
       " \"b'Striking Distance (1993)'\",\n",
       " \"b'Super Mario Bros. (1993)'\",\n",
       " \"b'Three Musketeers, The (1993)'\",\n",
       " \"b'Little Rascals, The (1994)'\",\n",
       " \"b'Brady Bunch Movie, The (1995)'\",\n",
       " \"b'Ghost (1990)'\",\n",
       " \"b'Batman (1989)'\",\n",
       " \"b'Pinocchio (1940)'\",\n",
       " \"b'Mission: Impossible (1996)'\",\n",
       " \"b'Thinner (1996)'\",\n",
       " \"b'Spy Hard (1996)'\",\n",
       " \"b'Close Shave, A (1995)'\",\n",
       " \"b'Jack (1996)'\",\n",
       " \"b'Kingpin (1996)'\",\n",
       " \"b'Nutty Professor, The (1996)'\",\n",
       " \"b'Very Brady Sequel, A (1996)'\",\n",
       " \"b'Tales from the Crypt Presents: Bordello of Blood (1996)'\",\n",
       " \"b'My Favorite Year (1982)'\",\n",
       " \"b'Apple Dumpling Gang, The (1975)'\",\n",
       " \"b'Old Yeller (1957)'\",\n",
       " \"b'Parent Trap, The (1961)'\",\n",
       " \"b'Cinderella (1950)'\",\n",
       " \"b'Mary Poppins (1964)'\",\n",
       " \"b'Alice in Wonderland (1951)'\",\n",
       " 'b\"William Shakespeare\\'s Romeo and Juliet (1996)\"',\n",
       " \"b'Aladdin and the King of Thieves (1996)'\",\n",
       " \"b'E.T. the Extra-Terrestrial (1982)'\",\n",
       " \"b'Children of the Corn: The Gathering (1996)'\",\n",
       " \"b'Bob Roberts (1992)'\",\n",
       " \"b'Transformers: The Movie, The (1986)'\",\n",
       " \"b'To Kill a Mockingbird (1962)'\",\n",
       " \"b'Harold and Maude (1971)'\",\n",
       " \"b'Day the Earth Stood Still, The (1951)'\",\n",
       " \"b'Duck Soup (1933)'\",\n",
       " \"b'Highlander (1986)'\",\n",
       " \"b'Fantasia (1940)'\",\n",
       " \"b'Heathers (1989)'\",\n",
       " \"b'Forbidden Planet (1956)'\",\n",
       " \"b'Butch Cassidy and the Sundance Kid (1969)'\",\n",
       " \"b'American Werewolf in London, An (1981)'\",\n",
       " 'b\"Amityville 1992: It\\'s About Time (1992)\"',\n",
       " \"b'Amityville 3-D (1983)'\",\n",
       " \"b'Amityville: A New Generation (1993)'\",\n",
       " \"b'Amityville II: The Possession (1982)'\",\n",
       " \"b'Amityville Horror, The (1979)'\",\n",
       " \"b'Amityville Curse, The (1990)'\",\n",
       " \"b'Birds, The (1963)'\",\n",
       " \"b'Blob, The (1958)'\",\n",
       " \"b'Body Snatcher, The (1945)'\",\n",
       " \"b'Burnt Offerings (1976)'\",\n",
       " \"b'Carrie (1976)'\",\n",
       " \"b'Omen, The (1976)'\",\n",
       " \"b'Star Trek: The Motion Picture (1979)'\",\n",
       " \"b'Star Trek V: The Final Frontier (1989)'\",\n",
       " \"b'Grease (1978)'\",\n",
       " \"b'Jaws 2 (1978)'\",\n",
       " \"b'Jaws 3-D (1983)'\",\n",
       " \"b'Bastard Out of Carolina (1996)'\",\n",
       " 'b\"Jackie Chan\\'s First Strike (1996)\"',\n",
       " \"b'Beverly Hills Ninja (1997)'\",\n",
       " \"b'Free Willy 3: The Rescue (1997)'\",\n",
       " \"b'Nixon (1995)'\",\n",
       " \"b'Cry, the Beloved Country (1995)'\",\n",
       " \"b'Crossing Guard, The (1995)'\",\n",
       " \"b'Smoke (1995)'\",\n",
       " \"b'Like Water For Chocolate (Como agua para chocolate) (1992)'\",\n",
       " \"b'Secret of Roan Inish, The (1994)'\",\n",
       " \"b'Vanya on 42nd Street (1994)'\",\n",
       " \"b'Jungle Book, The (1994)'\",\n",
       " \"b'Red Rock West (1992)'\",\n",
       " \"b'Bronx Tale, A (1993)'\",\n",
       " \"b'Rudy (1993)'\",\n",
       " \"b'Short Cuts (1993)'\",\n",
       " \"b'Tombstone (1993)'\",\n",
       " \"b'Courage Under Fire (1996)'\",\n",
       " \"b'Dragonheart (1996)'\",\n",
       " \"b'James and the Giant Peach (1996)'\",\n",
       " \"b'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)'\",\n",
       " \"b'Trainspotting (1996)'\",\n",
       " \"b'First Wives Club, The (1996)'\",\n",
       " \"b'Matilda (1996)'\",\n",
       " \"b'Philadelphia Story, The (1940)'\",\n",
       " \"b'Vertigo (1958)'\",\n",
       " \"b'North by Northwest (1959)'\",\n",
       " \"b'Apartment, The (1960)'\",\n",
       " \"b'Some Like It Hot (1959)'\",\n",
       " \"b'Casablanca (1942)'\",\n",
       " \"b'Maltese Falcon, The (1941)'\",\n",
       " \"b'My Fair Lady (1964)'\",\n",
       " \"b'Sabrina (1954)'\",\n",
       " \"b'Roman Holiday (1953)'\",\n",
       " \"b'Sunset Blvd. (1950)'\",\n",
       " \"b'Notorious (1946)'\",\n",
       " \"b'To Catch a Thief (1955)'\",\n",
       " \"b'Adventures of Robin Hood, The (1938)'\",\n",
       " \"b'East of Eden (1955)'\",\n",
       " \"b'Thin Man, The (1934)'\",\n",
       " \"b'His Girl Friday (1940)'\",\n",
       " \"b'Around the World in 80 Days (1956)'\",\n",
       " 'b\"It\\'s a Wonderful Life (1946)\"',\n",
       " \"b'Bringing Up Baby (1938)'\",\n",
       " \"b'African Queen, The (1951)'\",\n",
       " \"b'Cat on a Hot Tin Roof (1958)'\",\n",
       " \"b'Fly Away Home (1996)'\",\n",
       " \"b'Dumbo (1941)'\",\n",
       " \"b'Bananas (1971)'\",\n",
       " \"b'Candidate, The (1972)'\",\n",
       " \"b'Bonnie and Clyde (1967)'\",\n",
       " \"b'Dial M for Murder (1954)'\",\n",
       " \"b'Rebel Without a Cause (1955)'\",\n",
       " \"b'Streetcar Named Desire, A (1951)'\",\n",
       " \"b'People vs. Larry Flynt, The (1996)'\",\n",
       " \"b'My Left Foot (1989)'\",\n",
       " \"b'Magnificent Seven, The (1954)'\",\n",
       " \"b'Lawrence of Arabia (1962)'\",\n",
       " \"b'Wings of Desire (1987)'\",\n",
       " \"b'Third Man, The (1949)'\",\n",
       " \"b'Annie Hall (1977)'\",\n",
       " \"b'Boot, Das (1981)'\",\n",
       " \"b'Local Hero (1983)'\",\n",
       " \"b'Manhattan (1979)'\",\n",
       " 'b\"Miller\\'s Crossing (1990)\"',\n",
       " \"b'Treasure of the Sierra Madre, The (1948)'\",\n",
       " \"b'Great Escape, The (1963)'\",\n",
       " \"b'Deer Hunter, The (1978)'\",\n",
       " \"b'Down by Law (1986)'\",\n",
       " \"b'Cool Hand Luke (1967)'\",\n",
       " \"b'Great Dictator, The (1940)'\",\n",
       " \"b'Big Sleep, The (1946)'\",\n",
       " \"b'Ben-Hur (1959)'\",\n",
       " \"b'Gandhi (1982)'\",\n",
       " \"b'Killing Fields, The (1984)'\",\n",
       " \"b'My Life as a Dog (Mitt liv som hund) (1985)'\",\n",
       " \"b'Man Who Would Be King, The (1975)'\",\n",
       " \"b'Shine (1996)'\",\n",
       " \"b'Kama Sutra: A Tale of Love (1996)'\",\n",
       " \"b'Daytrippers, The (1996)'\",\n",
       " \"b'Traveller (1997)'\",\n",
       " \"b'Addicted to Love (1997)'\",\n",
       " \"b'Ponette (1996)'\",\n",
       " \"b'My Own Private Idaho (1991)'\",\n",
       " \"b'Anastasia (1997)'\",\n",
       " \"b'Mouse Hunt (1997)'\",\n",
       " \"b'Money Train (1995)'\",\n",
       " \"b'Mortal Kombat (1995)'\",\n",
       " \"b'Pocahontas (1995)'\",\n",
       " \"b'Mis\\\\xe9rables, Les (1995)'\",\n",
       " 'b\"Things to Do in Denver when You\\'re Dead (1995)\"',\n",
       " \"b'Vampire in Brooklyn (1995)'\",\n",
       " \"b'Broken Arrow (1996)'\",\n",
       " 'b\"Young Poisoner\\'s Handbook, The (1995)\"',\n",
       " \"b'NeverEnding Story III, The (1994)'\",\n",
       " \"b'Rob Roy (1995)'\",\n",
       " \"b'Die Hard: With a Vengeance (1995)'\",\n",
       " \"b'Lord of Illusions (1995)'\",\n",
       " \"b'Species (1995)'\",\n",
       " \"b'Walk in the Clouds, A (1995)'\",\n",
       " \"b'Waterworld (1995)'\",\n",
       " 'b\"White Man\\'s Burden (1995)\"',\n",
       " \"b'Wild Bill (1995)'\",\n",
       " \"b'Farinelli: il castrato (1994)'\",\n",
       " \"b'Heavenly Creatures (1994)'\",\n",
       " \"b'Interview with the Vampire (1994)'\",\n",
       " 'b\"Kid in King Arthur\\'s Court, A (1995)\"',\n",
       " 'b\"Mary Shelley\\'s Frankenstein (1994)\"',\n",
       " \"b'Quick and the Dead, The (1995)'\",\n",
       " 'b\"Stephen King\\'s The Langoliers (1995)\"',\n",
       " \"b'Tales from the Hood (1995)'\",\n",
       " \"b'Village of the Damned (1995)'\",\n",
       " \"b'Clear and Present Danger (1994)'\",\n",
       " 'b\"Wes Craven\\'s New Nightmare (1994)\"',\n",
       " \"b'Speed (1994)'\",\n",
       " \"b'Wolf (1994)'\",\n",
       " \"b'Wyatt Earp (1994)'\",\n",
       " \"b'Another Stakeout (1993)'\",\n",
       " \"b'Blown Away (1994)'\",\n",
       " \"b'Body Snatchers (1993)'\",\n",
       " \"b'Boxing Helena (1993)'\",\n",
       " 'b\"City Slickers II: The Legend of Curly\\'s Gold (1994)\"',\n",
       " \"b'Cliffhanger (1993)'\",\n",
       " \"b'Coneheads (1993)'\",\n",
       " \"b'Demolition Man (1993)'\",\n",
       " \"b'Fatal Instinct (1993)'\",\n",
       " \"b'Englishman Who Went Up a Hill, But Came Down a Mountain, The (1995)'\",\n",
       " \"b'Kalifornia (1993)'\",\n",
       " \"b'Piano, The (1993)'\",\n",
       " \"b'Romeo Is Bleeding (1993)'\",\n",
       " \"b'Secret Garden, The (1993)'\",\n",
       " \"b'Son in Law (1993)'\",\n",
       " \"b'Terminal Velocity (1994)'\",\n",
       " \"b'Hour of the Pig, The (1993)'\",\n",
       " \"b'Beauty and the Beast (1991)'\",\n",
       " \"b'Wild Bunch, The (1969)'\",\n",
       " \"b'Hellraiser: Bloodline (1996)'\",\n",
       " \"b'Primal Fear (1996)'\",\n",
       " \"b'True Crime (1995)'\",\n",
       " \"b'Stalingrad (1993)'\",\n",
       " \"b'Heavy (1995)'\",\n",
       " \"b'Fan, The (1996)'\",\n",
       " \"b'Hunchback of Notre Dame, The (1996)'\",\n",
       " \"b'Eraser (1996)'\",\n",
       " \"b'Big Squeeze, The (1996)'\",\n",
       " \"b'Police Story 4: Project S (Chao ji ji hua) (1993)'\",\n",
       " 'b\"Daniel Defoe\\'s Robinson Crusoe (1996)\"',\n",
       " \"b'For Whom the Bell Tolls (1943)'\",\n",
       " \"b'American in Paris, An (1951)'\",\n",
       " \"b'Rear Window (1954)'\",\n",
       " \"b'It Happened One Night (1934)'\",\n",
       " \"b'Meet Me in St. Louis (1944)'\",\n",
       " \"b'All About Eve (1950)'\",\n",
       " \"b'Rebecca (1940)'\",\n",
       " \"b'Spellbound (1945)'\",\n",
       " \"b'Father of the Bride (1950)'\",\n",
       " \"b'Gigi (1958)'\",\n",
       " \"b'Laura (1944)'\",\n",
       " \"b'Lost Horizon (1937)'\",\n",
       " \"b'My Man Godfrey (1936)'\",\n",
       " \"b'Giant (1956)'\",\n",
       " \"b'39 Steps, The (1935)'\",\n",
       " \"b'Night of the Living Dead (1968)'\",\n",
       " \"b'Blue Angel, The (Blaue Engel, Der) (1930)'\",\n",
       " \"b'Picnic (1955)'\",\n",
       " \"b'Extreme Measures (1996)'\",\n",
       " \"b'Chamber, The (1996)'\",\n",
       " \"b'Davy Crockett, King of the Wild Frontier (1955)'\",\n",
       " \"b'Swiss Family Robinson (1960)'\",\n",
       " \"b'Angels in the Outfield (1994)'\",\n",
       " \"b'Three Caballeros, The (1945)'\",\n",
       " \"b'Sword in the Stone, The (1963)'\",\n",
       " \"b'So Dear to My Heart (1949)'\",\n",
       " \"b'Robin Hood: Prince of Thieves (1991)'\",\n",
       " \"b'Sleepers (1996)'\",\n",
       " \"b'Victor/Victoria (1982)'\",\n",
       " \"b'Great Race, The (1965)'\",\n",
       " \"b'Crying Game, The (1992)'\",\n",
       " 'b\"Sophie\\'s Choice (1982)\"',\n",
       " \"b'Christmas Carol, A (1938)'\",\n",
       " 'b\"Microcosmos: Le peuple de l\\'herbe (1996)\"',\n",
       " \"b'Fog, The (1980)'\",\n",
       " \"b'Escape from New York (1981)'\",\n",
       " \"b'Howling, The (1981)'\",\n",
       " \"b'Return of Martin Guerre, The (Retour de Martin Guerre, Le) (1982)'\",\n",
       " \"b'Tin Drum, The (Blechtrommel, Die) (1979)'\",\n",
       " \"b'Cook the Thief His Wife & Her Lover, The (1989)'\",\n",
       " \"b'Paths of Glory (1957)'\",\n",
       " \"b'Grifters, The (1990)'\",\n",
       " \"b'The Innocent (1994)'\",\n",
       " \"b'Thin Blue Line, The (1988)'\",\n",
       " \"b'Paris Is Burning (1990)'\",\n",
       " \"b'Once Upon a Time in the West (1969)'\",\n",
       " \"b'Ran (1985)'\",\n",
       " \"b'Quiet Man, The (1952)'\",\n",
       " \"b'Once Upon a Time in America (1984)'\",\n",
       " \"b'Seventh Seal, The (Sjunde inseglet, Det) (1957)'\",\n",
       " \"b'Glory (1989)'\",\n",
       " \"b'Rosencrantz and Guildenstern Are Dead (1990)'\",\n",
       " \"b'Touch of Evil (1958)'\",\n",
       " \"b'Chinatown (1974)'\",\n",
       " \"b'Stand by Me (1986)'\",\n",
       " \"b'M (1931)'\",\n",
       " \"b'Manchurian Candidate, The (1962)'\",\n",
       " \"b'Pump Up the Volume (1990)'\",\n",
       " \"b'Arsenic and Old Lace (1944)'\",\n",
       " \"b'Fried Green Tomatoes (1991)'\",\n",
       " \"b'High Noon (1952)'\",\n",
       " \"b'Somewhere in Time (1980)'\",\n",
       " \"b'Being There (1979)'\",\n",
       " \"b'Paris, Texas (1984)'\",\n",
       " \"b'Alien 3 (1992)'\",\n",
       " 'b\"Blood For Dracula (Andy Warhol\\'s Dracula) (1974)\"',\n",
       " \"b'Audrey Rose (1977)'\",\n",
       " \"b'Blood Beach (1981)'\",\n",
       " \"b'Body Parts (1991)'\",\n",
       " \"b'Body Snatchers (1993)'\",\n",
       " \"b'Bride of Frankenstein (1935)'\",\n",
       " \"b'Candyman (1992)'\",\n",
       " \"b'Cape Fear (1962)'\",\n",
       " \"b'Cat People (1982)'\",\n",
       " \"b'Nosferatu (Nosferatu, eine Symphonie des Grauens) (1922)'\",\n",
       " \"b'Crucible, The (1996)'\",\n",
       " \"b'Fire on the Mountain (1996)'\",\n",
       " \"b'Volcano (1997)'\",\n",
       " \"b'Conan the Barbarian (1981)'\",\n",
       " \"b'Kull the Conqueror (1997)'\",\n",
       " \"b'Wishmaster (1997)'\",\n",
       " \"b'I Know What You Did Last Summer (1997)'\",\n",
       " \"b'Rocket Man (1997)'\",\n",
       " \"b'In the Line of Fire (1993)'\",\n",
       " \"b'Executive Decision (1996)'\",\n",
       " \"b'Perfect World, A (1993)'\",\n",
       " 'b\"McHale\\'s Navy (1997)\"',\n",
       " \"b'Leave It to Beaver (1997)'\",\n",
       " \"b'Jackal, The (1997)'\",\n",
       " \"b'Seven Years in Tibet (1997)'\",\n",
       " \"b'Dark City (1998)'\",\n",
       " \"b'American President, The (1995)'\",\n",
       " \"b'Casino (1995)'\",\n",
       " \"b'Persuasion (1995)'\",\n",
       " \"b'Kicking and Screaming (1995)'\",\n",
       " \"b'City Hall (1996)'\",\n",
       " \"b'Basketball Diaries, The (1995)'\",\n",
       " \"b'Browning Version, The (1994)'\",\n",
       " \"b'Little Women (1994)'\",\n",
       " \"b'Miami Rhapsody (1995)'\",\n",
       " \"b'Wonderful, Horrible Life of Leni Riefenstahl, The (1993)'\",\n",
       " \"b'Barcelona (1994)'\",\n",
       " 'b\"Widows\\' Peak (1994)\"',\n",
       " \"b'House of the Spirits, The (1993)'\",\n",
       " 'b\"Singin\\' in the Rain (1952)\"',\n",
       " \"b'Bad Moon (1996)'\",\n",
       " \"b'Enchanted April (1991)'\",\n",
       " \"b'Sex, Lies, and Videotape (1989)'\",\n",
       " \"b'Strictly Ballroom (1992)'\",\n",
       " \"b'Better Off Dead... (1985)'\",\n",
       " \"b'Substance of Fire, The (1996)'\",\n",
       " \"b'Tin Men (1987)'\",\n",
       " \"b'Othello (1995)'\",\n",
       " \"b'Carrington (1995)'\",\n",
       " \"b'To Die For (1995)'\",\n",
       " \"b'Home for the Holidays (1995)'\",\n",
       " \"b'Juror, The (1996)'\",\n",
       " \"b'In the Bleak Midwinter (1995)'\",\n",
       " \"b'Canadian Bacon (1994)'\",\n",
       " \"b'First Knight (1995)'\",\n",
       " \"b'Mallrats (1995)'\",\n",
       " \"b'Nine Months (1995)'\",\n",
       " \"b'Boys on the Side (1995)'\",\n",
       " \"b'Circle of Friends (1995)'\",\n",
       " \"b'Exit to Eden (1994)'\",\n",
       " \"b'Fluke (1995)'\",\n",
       " \"b'Immortal Beloved (1994)'\",\n",
       " \"b'Junior (1994)'\",\n",
       " \"b'Nell (1994)'\",\n",
       " \"b'Queen Margot (Reine Margot, La) (1994)'\",\n",
       " \"b'Corrina, Corrina (1994)'\",\n",
       " \"b'Dave (1993)'\",\n",
       " \"b'Go Fish (1994)'\",\n",
       " \"b'Made in America (1993)'\",\n",
       " \"b'Philadelphia (1993)'\",\n",
       " \"b'Shadowlands (1993)'\",\n",
       " \"b'Sirens (1994)'\",\n",
       " \"b'Threesome (1994)'\",\n",
       " \"b'Pretty Woman (1990)'\",\n",
       " \"b'Jane Eyre (1996)'\",\n",
       " \"b'Last Supper, The (1995)'\",\n",
       " \"b'Ransom (1996)'\",\n",
       " \"b'Crow: City of Angels, The (1996)'\",\n",
       " \"b'Michael Collins (1996)'\",\n",
       " \"b'Ruling Class, The (1972)'\",\n",
       " \"b'Real Genius (1985)'\",\n",
       " \"b'Benny & Joon (1993)'\",\n",
       " \"b'Saint, The (1997)'\",\n",
       " \"b'MatchMaker, The (1997)'\",\n",
       " \"b'Amistad (1997)'\",\n",
       " \"b'Tomorrow Never Dies (1997)'\",\n",
       " \"b'Replacement Killers, The (1998)'\",\n",
       " \"b'Burnt By the Sun (1994)'\",\n",
       " \"b'Red Corner (1997)'\",\n",
       " \"b'Jumanji (1995)'\",\n",
       " \"b'Father of the Bride Part II (1995)'\",\n",
       " \"b'Across the Sea of Time (1995)'\",\n",
       " \"b'Lawnmower Man 2: Beyond Cyberspace (1996)'\",\n",
       " \"b'Fair Game (1995)'\",\n",
       " \"b'Screamers (1995)'\",\n",
       " \"b'Nick of Time (1995)'\",\n",
       " \"b'Beautiful Girls (1996)'\",\n",
       " \"b'Happy Gilmore (1996)'\",\n",
       " \"b'If Lucy Fell (1996)'\",\n",
       " \"b'Boomerang (1992)'\",\n",
       " \"b'Man of the Year (1995)'\",\n",
       " \"b'Addiction, The (1995)'\",\n",
       " \"b'Casper (1995)'\",\n",
       " \"b'Congo (1995)'\",\n",
       " \"b'Devil in a Blue Dress (1995)'\",\n",
       " \"b'Johnny Mnemonic (1995)'\",\n",
       " \"b'Kids (1995)'\",\n",
       " \"b'Mute Witness (1994)'\",\n",
       " \"b'Prophecy, The (1995)'\",\n",
       " \"b'Something to Talk About (1995)'\",\n",
       " \"b'Three Wishes (1995)'\",\n",
       " \"b'Castle Freak (1995)'\",\n",
       " \"b'Don Juan DeMarco (1995)'\",\n",
       " \"b'Drop Zone (1994)'\",\n",
       " \"b'Dumb & Dumber (1994)'\",\n",
       " \"b'French Kiss (1995)'\",\n",
       " \"b'Little Odessa (1994)'\",\n",
       " \"b'Milk Money (1994)'\",\n",
       " \"b'Beyond Bedlam (1993)'\",\n",
       " \"b'Only You (1994)'\",\n",
       " \"b'Perez Family, The (1995)'\",\n",
       " \"b'Roommates (1995)'\",\n",
       " \"b'Relative Fear (1994)'\",\n",
       " \"b'Swimming with Sharks (1995)'\",\n",
       " \"b'Tommy Boy (1995)'\",\n",
       " \"b'Baby-Sitters Club, The (1995)'\",\n",
       " \"b'Bullets Over Broadway (1994)'\",\n",
       " \"b'Crooklyn (1994)'\",\n",
       " \"b'It Could Happen to You (1994)'\",\n",
       " \"b'Richie Rich (1994)'\",\n",
       " \"b'Speechless (1994)'\",\n",
       " \"b'Timecop (1994)'\",\n",
       " \"b'Bad Company (1995)'\",\n",
       " \"b'Boys Life (1995)'\",\n",
       " \"b'In the Mouth of Madness (1995)'\",\n",
       " \"b'Air Up There, The (1994)'\",\n",
       " \"b'Hard Target (1993)'\",\n",
       " \"b'Heaven & Earth (1993)'\",\n",
       " \"b'Jimmy Hollywood (1994)'\",\n",
       " \"b'Manhattan Murder Mystery (1993)'\",\n",
       " \"b'Menace II Society (1993)'\",\n",
       " \"b'Poetic Justice (1993)'\",\n",
       " \"b'Program, The (1993)'\",\n",
       " \"b'Rising Sun (1993)'\",\n",
       " \"b'Shadow, The (1994)'\",\n",
       " \"b'Thirty-Two Short Films About Glenn Gould (1993)'\",\n",
       " \"b'Andre (1994)'\",\n",
       " \"b'Celluloid Closet, The (1995)'\",\n",
       " \"b'Great Day in Harlem, A (1994)'\",\n",
       " \"b'One Fine Day (1996)'\",\n",
       " \"b'Candyman: Farewell to the Flesh (1995)'\",\n",
       " \"b'Frisk (1995)'\",\n",
       " \"b'Girl 6 (1996)'\",\n",
       " \"b'Eddie (1996)'\",\n",
       " \"b'Space Jam (1996)'\",\n",
       " \"b'Mrs. Winterbourne (1996)'\",\n",
       " \"b'Faces (1968)'\",\n",
       " \"b'Mulholland Falls (1996)'\",\n",
       " \"b'Great White Hype, The (1996)'\",\n",
       " \"b'Arrival, The (1996)'\",\n",
       " \"b'Phantom, The (1996)'\",\n",
       " \"b'Daylight (1996)'\",\n",
       " \"b'Alaska (1996)'\",\n",
       " \"b'Fled (1996)'\",\n",
       " \"b'Power 98 (1995)'\",\n",
       " \"b'Escape from L.A. (1996)'\",\n",
       " \"b'Bogus (1996)'\",\n",
       " \"b'Bulletproof (1996)'\",\n",
       " \"b'Halloween: The Curse of Michael Myers (1995)'\",\n",
       " \"b'Gay Divorcee, The (1934)'\",\n",
       " \"b'Ninotchka (1939)'\",\n",
       " \"b'Meet John Doe (1941)'\",\n",
       " \"b'In the Line of Duty 2 (1987)'\",\n",
       " \"b'Loch Ness (1995)'\",\n",
       " \"b'Last Man Standing (1996)'\",\n",
       " \"b'Glimmer Man, The (1996)'\",\n",
       " \"b'Pollyanna (1960)'\",\n",
       " \"b'Shaggy Dog, The (1959)'\",\n",
       " \"b'Freeway (1996)'\",\n",
       " \"b'That Thing You Do! (1996)'\",\n",
       " \"b'To Gillian on Her 37th Birthday (1996)'\",\n",
       " \"b'Looking for Richard (1996)'\",\n",
       " \"b'Murder, My Sweet (1944)'\",\n",
       " \"b'Days of Thunder (1990)'\",\n",
       " \"b'Perfect Candidate, A (1996)'\",\n",
       " \"b'Two or Three Things I Know About Her (1966)'\",\n",
       " \"b'Bloody Child, The (1996)'\",\n",
       " \"b'Braindead (1992)'\",\n",
       " \"b'Bad Taste (1987)'\",\n",
       " \"b'Diva (1981)'\",\n",
       " \"b'Night on Earth (1991)'\",\n",
       " \"b'Paris Was a Woman (1995)'\",\n",
       " \"b'Amityville: Dollhouse (1996)'\",\n",
       " 'b\"April Fool\\'s Day (1986)\"',\n",
       " \"b'Believers, The (1987)'\",\n",
       " \"b'Nosferatu a Venezia (1986)'\",\n",
       " \"b'Jingle All the Way (1996)'\",\n",
       " \"b'Garden of Finzi-Contini, The (Giardino dei Finzi-Contini, Il) (1970)'\",\n",
       " \"b'My Fellow Americans (1996)'\",\n",
       " \"b'Ice Storm, The (1997)'\",\n",
       " \"b'Michael (1996)'\",\n",
       " \"b'Whole Wide World, The (1996)'\",\n",
       " \"b'Hearts and Minds (1996)'\",\n",
       " \"b'Fools Rush In (1997)'\",\n",
       " \"b'Touch (1997)'\",\n",
       " \"b'Vegas Vacation (1997)'\",\n",
       " \"b'Love Jones (1997)'\",\n",
       " \"b'Picture Perfect (1997)'\",\n",
       " \"b'Career Girls (1997)'\",\n",
       " 'b\"She\\'s So Lovely (1997)\"',\n",
       " \"b'Money Talks (1997)'\",\n",
       " \"b'Excess Baggage (1997)'\",\n",
       " \"b'That Darn Cat! (1997)'\",\n",
       " \"b'Peacemaker, The (1997)'\",\n",
       " \"b'Soul Food (1997)'\",\n",
       " \"b'Money Talks (1997)'\",\n",
       " \"b'Washington Square (1997)'\",\n",
       " \"b'Telling Lies in America (1997)'\",\n",
       " \"b'Year of the Horse (1997)'\",\n",
       " \"b'Phantoms (1998)'\",\n",
       " \"b'Life Less Ordinary, A (1997)'\",\n",
       " 'b\"Eve\\'s Bayou (1997)\"',\n",
       " \"b'One Night Stand (1997)'\",\n",
       " \"b'Tango Lesson, The (1997)'\",\n",
       " \"b'Mortal Kombat: Annihilation (1997)'\",\n",
       " \"b'Bent (1997)'\",\n",
       " \"b'Flubber (1997)'\",\n",
       " \"b'For Richer or Poorer (1997)'\",\n",
       " \"b'Home Alone 3 (1997)'\",\n",
       " \"b'Scream 2 (1997)'\",\n",
       " \"b'Sweet Hereafter, The (1997)'\",\n",
       " \"b'Time Tracers (1995)'\",\n",
       " \"b'Postman, The (1997)'\",\n",
       " \"b'Winter Guest, The (1997)'\",\n",
       " \"b'Kundun (1997)'\",\n",
       " \"b'Mr. Magoo (1997)'\",\n",
       " \"b'Big Lebowski, The (1998)'\",\n",
       " \"b'Afterglow (1997)'\",\n",
       " \"b'Ma vie en rose (My Life in Pink) (1997)'\",\n",
       " \"b'Great Expectations (1998)'\",\n",
       " \"b'Oscar & Lucinda (1997)'\",\n",
       " \"b'Vermin (1998)'\",\n",
       " \"b'Half Baked (1998)'\",\n",
       " \"b'Dangerous Beauty (1998)'\",\n",
       " \"b'Nil By Mouth (1997)'\",\n",
       " \"b'Twilight (1998)'\",\n",
       " \"b'U.S. Marshalls (1998)'\",\n",
       " \"b'Love and Death on Long Island (1997)'\",\n",
       " \"b'Wild Things (1998)'\",\n",
       " \"b'Primary Colors (1998)'\",\n",
       " \"b'Lost in Space (1998)'\",\n",
       " \"b'Mercury Rising (1998)'\",\n",
       " \"b'City of Angels (1998)'\",\n",
       " \"b'City of Lost Children, The (1995)'\",\n",
       " \"b'Two Bits (1995)'\",\n",
       " \"b'Farewell My Concubine (1993)'\",\n",
       " \"b'Dead Man (1995)'\",\n",
       " \"b'Raise the Red Lantern (1991)'\",\n",
       " \"b'White Squall (1996)'\",\n",
       " \"b'Unforgettable (1996)'\",\n",
       " \"b'Down Periscope (1996)'\",\n",
       " \"b'Flower of My Secret, The (Flor de mi secreto, La) (1995)'\",\n",
       " \"b'Craft, The (1996)'\",\n",
       " \"b'Harriet the Spy (1996)'\",\n",
       " \"b'Chain Reaction (1996)'\",\n",
       " \"b'Island of Dr. Moreau, The (1996)'\",\n",
       " \"b'First Kid (1996)'\",\n",
       " \"b'Funeral, The (1996)'\",\n",
       " 'b\"Preacher\\'s Wife, The (1996)\"',\n",
       " \"b'Paradise Road (1997)'\",\n",
       " \"b'Brassed Off (1996)'\",\n",
       " \"b'Thousand Acres, A (1997)'\",\n",
       " \"b'Smile Like Yours, A (1997)'\",\n",
       " \"b'Murder in the First (1995)'\",\n",
       " \"b'Airheads (1994)'\",\n",
       " \"b'With Honors (1994)'\",\n",
       " 'b\"What\\'s Love Got to Do with It (1993)\"',\n",
       " \"b'Killing Zoe (1994)'\",\n",
       " \"b'Renaissance Man (1994)'\",\n",
       " \"b'Charade (1963)'\",\n",
       " \"b'Fox and the Hound, The (1981)'\",\n",
       " \"b'Big Blue, The (Grand bleu, Le) (1988)'\",\n",
       " \"b'Booty Call (1997)'\",\n",
       " \"b'How to Make an American Quilt (1995)'\",\n",
       " \"b'Georgia (1995)'\",\n",
       " \"b'Indian in the Cupboard, The (1995)'\",\n",
       " \"b'Blue in the Face (1995)'\",\n",
       " \"b'Unstrung Heroes (1995)'\",\n",
       " \"b'Unzipped (1995)'\",\n",
       " \"b'Before Sunrise (1995)'\",\n",
       " 'b\"Nobody\\'s Fool (1994)\"',\n",
       " \"b'Pushing Hands (1992)'\",\n",
       " \"b'To Live (Huozhe) (1994)'\",\n",
       " \"b'Dazed and Confused (1993)'\",\n",
       " \"b'Naked (1993)'\",\n",
       " \"b'Orlando (1993)'\",\n",
       " \"b'Ruby in Paradise (1993)'\",\n",
       " \"b'Some Folks Call It a Sling Blade (1993)'\",\n",
       " \"b'Month by the Lake, A (1995)'\",\n",
       " \"b'Funny Face (1957)'\",\n",
       " \"b'Affair to Remember, An (1957)'\",\n",
       " \"b'Little Lord Fauntleroy (1936)'\",\n",
       " \"b'Inspector General, The (1949)'\",\n",
       " \"b'Winnie the Pooh and the Blustery Day (1968)'\",\n",
       " \"b'Hear My Song (1991)'\",\n",
       " \"b'Mediterraneo (1991)'\",\n",
       " \"b'Passion Fish (1992)'\",\n",
       " \"b'Grateful Dead (1995)'\",\n",
       " \"b'Eye for an Eye (1996)'\",\n",
       " \"b'Fear (1996)'\",\n",
       " \"b'Solo (1996)'\",\n",
       " \"b'Substitute, The (1996)'\",\n",
       " 'b\"Heaven\\'s Prisoners (1996)\"',\n",
       " \"b'Trigger Effect, The (1996)'\",\n",
       " \"b'Mother Night (1996)'\",\n",
       " \"b'Dangerous Ground (1997)'\",\n",
       " \"b'Maximum Risk (1996)'\",\n",
       " 'b\"Rich Man\\'s Wife, The (1996)\"',\n",
       " \"b'Shadow Conspiracy (1997)'\",\n",
       " \"b'Blood & Wine (1997)'\",\n",
       " \"b'Turbulence (1997)'\",\n",
       " \"b'Underworld (1997)'\",\n",
       " \"b'Beautician and the Beast, The (1997)'\",\n",
       " 'b\"Cats Don\\'t Dance (1997)\"',\n",
       " \"b'Anna Karenina (1997)'\",\n",
       " \"b'Keys to Tulsa (1997)'\",\n",
       " \"b'Head Above Water (1996)'\",\n",
       " \"b'Hercules (1997)'\",\n",
       " \"b'Last Time I Committed Suicide, The (1997)'\",\n",
       " \"b'Kiss Me, Guido (1997)'\",\n",
       " \"b'Big Green, The (1995)'\",\n",
       " \"b'Stuart Saves His Family (1995)'\",\n",
       " \"b'Cabin Boy (1994)'\",\n",
       " \"b'Clean Slate (1994)'\",\n",
       " \"b'Lightning Jack (1994)'\",\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(item_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Chasing Amy (1997)' [246, 268]\n",
      "b'Kull the Conqueror (1997)' [266, 680]\n",
      "b\"Ulee's Gold (1997)\" [297, 303]\n",
      "b'Fly Away Home (1996)' [304, 500]\n",
      "b'Ice Storm, The (1997)' [305, 865]\n",
      "b'Deceiver (1997)' [309, 1606]\n",
      "b'Desperate Measures (1998)' [329, 348]\n",
      "b'Body Snatchers (1993)' [573, 670]\n",
      "b'Substance of Fire, The (1996)' [711, 1658]\n",
      "b'Money Talks (1997)' [876, 881]\n",
      "b'That Darn Cat! (1997)' [878, 1003]\n",
      "b'Hugo Pool (1997)' [1175, 1617]\n",
      "b'Chairman of the Board (1998)' [1234, 1654]\n",
      "b'Designated Mourner, The (1997)' [1256, 1257]\n",
      "b'Hurricane Streets (1998)' [1395, 1607]\n",
      "b'Sliding Doors (1998)' [1429, 1680]\n",
      "b'Nightwatch (1997)' [1477, 1625]\n",
      "b'Butcher Boy, The (1998)' [1645, 1650]\n"
     ]
    }
   ],
   "source": [
    "duplicates_item_dict = {}\n",
    "i = 0\n",
    "\n",
    "for id,name in list(item_dict.items()):\n",
    "    if name not in duplicates_item_dict:\n",
    "        duplicates_item_dict[name] = [id]\n",
    "    else:\n",
    "        duplicates_item_dict[name] = duplicates_item_dict[name]+[id]\n",
    "            \n",
    "\n",
    "# show hte duplicated titles\n",
    "for k,v in list(duplicates_item_dict.items()):\n",
    "    if len(v)>1:\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dict where the key are the original ids, and the values are the unique one. \n",
    "We will use this dictionary to remove duplicates in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<enumerate object at 0x000000AAE8C21E10>\n"
     ]
    }
   ],
   "source": [
    "print(enumerate(duplicates_item_dict.values()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id_item_dict ={}\n",
    "for id_nuevo, lista_id_viejo in enumerate(duplicates_item_dict.values()) :\n",
    "    for id_viejo in lista_id_viejo:\n",
    "        unique_id_item_dict[id_viejo] = id_nuevo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create another dict mapping moving titles to this new unique id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_item_dict = {unique_id_item_dict[k]:v \n",
    "                    for k,v in item_dict.items()}\n",
    "assert(len(set(unique_item_dict.keys())) == \n",
    "       len(set(unique_item_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1664"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(item_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use our `returnItemId()` mehtod safely =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(239, \"b'Beavis and Butt-head Do America (1996)'\"),\n",
       " (431, \"b'Butch Cassidy and the Sundance Kid (1969)'\"),\n",
       " (575,\n",
       "  \"b'Englishman Who Went Up a Hill, But Came Down a Mountain, The (1995)'\"),\n",
       " (1390, \"b'M. Butterfly (1993)'\"),\n",
       " (1448, \"b'Madame Butterfly (1995)'\"),\n",
       " (1601, \"b'Reluctant Debutante, The (1958)'\"),\n",
       " (1607, \"b'Butterfly Kiss (1995)'\"),\n",
       " (1630, \"b'Butcher Boy, The (1998)'\")]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returnItemId('but', unique_item_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(240, \"b'Beavis and Butt-head Do America (1996)'\"),\n",
       " (435, \"b'Butch Cassidy and the Sundance Kid (1969)'\"),\n",
       " (580,\n",
       "  \"b'Englishman Who Went Up a Hill, But Came Down a Mountain, The (1995)'\"),\n",
       " (1401, \"b'M. Butterfly (1993)'\"),\n",
       " (1459, \"b'Madame Butterfly (1995)'\"),\n",
       " (1614, \"b'Reluctant Debutante, The (1958)'\"),\n",
       " (1621, \"b'Butterfly Kiss (1995)'\"),\n",
       " (1645, \"b'Butcher Boy, The (1998)'\"),\n",
       " (1650, \"b'Butcher Boy, The (1998)'\")]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returnItemId('but', item_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Train and test sets\n",
    "\n",
    "GroupLens provides several splits of the dataset, so that we can check the goodness of our algorithms. See the README file for more  details. Here we will use one of such splits.\n",
    "\n",
    "Please notice that we have to correct for the non-unique movie's id issue!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README\n",
      "allbut.pl\n",
      "mku.sh\n",
      "u.data\n",
      "u.genre\n",
      "u.info\n",
      "u.item\n",
      "u.occupation\n",
      "u.user\n",
      "u1.base\n",
      "u1.test\n",
      "u2.base\n",
      "u2.test\n",
      "u3.base\n",
      "u3.test\n",
      "u4.base\n",
      "u4.test\n",
      "u5.base\n",
      "u5.test\n",
      "ua.base\n",
      "ua.test\n",
      "ub.base\n",
      "ub.test\n"
     ]
    }
   ],
   "source": [
    "!ls $data_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t1\t5\t874965758\n",
      "1\t2\t3\t876893171\n",
      "1\t3\t4\t878542960\n",
      "1\t4\t3\t876893119\n",
      "1\t5\t3\t889751712\n",
      "1\t6\t5\t887431973\n",
      "1\t7\t4\t875071561\n",
      "1\t8\t1\t875072484\n",
      "1\t9\t5\t878543541\n",
      "1\t10\t3\t875693118\n"
     ]
    }
   ],
   "source": [
    "trainfile = os.path.join(data_root, 'ua.base')\n",
    "!head $trainfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 943 users, 1680 itmes and 90570 pairs in the train set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1        1       5  874965758\n",
       "1        1        2       3  876893171\n",
       "2        1        3       4  878542960\n",
       "3        1        4       3  876893119\n",
       "4        1        5       3  889751712"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "trainfile = os.path.join(data_root, \"ua.base\")\n",
    "train = pd.read_csv(trainfile, sep='\\t', names=columns)\n",
    "print('There are %s users, %s itmes and %s pairs in the train set' \\\n",
    "      %(train.user_id.unique().shape[0], train.item_id.unique().shape[0], train.shape[0]))\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 943 users, 1129 itmes and 9430 pairs in the test set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>887431883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>878542699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>878542420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>874965739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>878542201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1       20       4  887431883\n",
       "1        1       33       4  878542699\n",
       "2        1       61       4  878542420\n",
       "3        1      117       3  874965739\n",
       "4        1      155       2  878542201"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "testfile = os.path.join(data_root, \"ua.test\")\n",
    "test = pd.read_csv(testfile, sep='\\t', names=columns)\n",
    "print('There are %s users, %s itmes and %s pairs in the test set' \\\n",
    "      %(test.user_id.unique().shape[0], test.item_id.unique().shape[0], test.shape[0]))\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting for non-unique movies id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now there are 1662 unique items in traint set\n"
     ]
    }
   ],
   "source": [
    "train['item_id'] = train['item_id'].apply(\n",
    "    lambda id: unique_id_item_dict[id])\n",
    "print('Now there are %s unique items in traint set' \n",
    "      % train.item_id.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now there are 1119 unique items in test set\n"
     ]
    }
   ],
   "source": [
    "test['item_id'] = test['item_id'].apply(\n",
    "    lambda id: unique_id_item_dict[id])\n",
    "print('Now there are %s unique items in test set' \n",
    "      % test.item_id.unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='popular'></a>\n",
    "## 2. Most popular movies\n",
    "\n",
    "Recommending popular items is a simple, yet quite effective baseline for recommendation. Indeed, most RS suffer from a strong *popularity bias*, i.e. they tend to recommend popular items more frequently than they should -just because suggesting what is popular is effective!-. There is a lot of research  devote to understand this behaviour and to develop recipies to avoid it. \n",
    "\n",
    "Movies can be ranked according to different popularity metrics:\n",
    "* Most rated movie (it is assumed that this is the most watched movie)\n",
    "* Most positively rated movie (rating > 4.0)\n",
    "* Highest rated movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Most rated movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id', 'item_id', 'rating', 'timestamp']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the train dataset by item and count the number of users using Pandas\n",
    "mostRated = train.groupby('item_id').count()\n",
    "# sort in descending order\n",
    "mostRatedSorted = mostRated.sort_values('rating',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>495</td>\n",
       "      <td>495</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>443</td>\n",
       "      <td>443</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>412</td>\n",
       "      <td>412</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>392</td>\n",
       "      <td>392</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>384</td>\n",
       "      <td>384</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>379</td>\n",
       "      <td>379</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>352</td>\n",
       "      <td>352</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>348</td>\n",
       "      <td>348</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>347</td>\n",
       "      <td>347</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>346</td>\n",
       "      <td>346</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>335</td>\n",
       "      <td>335</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>330</td>\n",
       "      <td>330</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>322</td>\n",
       "      <td>322</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>322</td>\n",
       "      <td>322</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>311</td>\n",
       "      <td>311</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>311</td>\n",
       "      <td>311</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>308</td>\n",
       "      <td>308</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>280</td>\n",
       "      <td>280</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1662 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  rating  timestamp\n",
       "item_id                            \n",
       "49           495     495        495\n",
       "99           443     443        443\n",
       "180          439     439        439\n",
       "257          412     412        412\n",
       "284          400     400        400\n",
       "292          398     398        398\n",
       "0            392     392        392\n",
       "286          386     386        386\n",
       "120          384     384        384\n",
       "173          379     379        379\n",
       "126          352     352        352\n",
       "97           350     350        350\n",
       "55           348     348        348\n",
       "298          347     347        347\n",
       "6            346     346        346\n",
       "236          335     335        335\n",
       "171          330     330        330\n",
       "245          322     322        322\n",
       "221          322     322        322\n",
       "116          320     320        320\n",
       "78           311     311        311\n",
       "203          311     311        311\n",
       "209          308     308        308\n",
       "401          303     303        303\n",
       "172          300     300        300\n",
       "150          293     293        293\n",
       "68           292     292        292\n",
       "167          292     292        292\n",
       "194          282     282        282\n",
       "21           280     280        280\n",
       "...          ...     ...        ...\n",
       "1564           1       1          1\n",
       "1565           1       1          1\n",
       "1566           1       1          1\n",
       "1568           1       1          1\n",
       "1569           1       1          1\n",
       "1570           1       1          1\n",
       "1572           1       1          1\n",
       "1573           1       1          1\n",
       "1575           1       1          1\n",
       "1554           1       1          1\n",
       "1553           1       1          1\n",
       "1552           1       1          1\n",
       "823            1       1          1\n",
       "1499           1       1          1\n",
       "1504           1       1          1\n",
       "850            1       1          1\n",
       "1514           1       1          1\n",
       "1515           1       1          1\n",
       "845            1       1          1\n",
       "1522           1       1          1\n",
       "1525           1       1          1\n",
       "1551           1       1          1\n",
       "807            1       1          1\n",
       "1532           1       1          1\n",
       "1535           1       1          1\n",
       "1537           1       1          1\n",
       "1546           1       1          1\n",
       "1548           1       1          1\n",
       "1550           1       1          1\n",
       "1663           1       1          1\n",
       "\n",
       "[1662 rows x 3 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostRatedSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "49",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2441\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2442\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 49",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-4499a9664326>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     [np.array([row, unique_item_dict[row], \n\u001b[0;32m      4\u001b[0m                mostRatedSorted[row]], dtype=np.object)\n\u001b[1;32m----> 5\u001b[1;33m      for row in mostRatedSorted.index])\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmostRatedMovies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-120-4499a9664326>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m     [np.array([row, unique_item_dict[row], \n\u001b[0;32m      4\u001b[0m                mostRatedSorted[row]], dtype=np.object)\n\u001b[1;32m----> 5\u001b[1;33m      for row in mostRatedSorted.index])\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmostRatedMovies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1962\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1964\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1969\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1970\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1971\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1973\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1645\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3590\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2442\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2444\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 49"
     ]
    }
   ],
   "source": [
    "# Return a numpy array of np.array([id, title, frequency])\n",
    "mostRatedMovies = np.array(\n",
    "    [np.array([row, unique_item_dict[row], \n",
    "               mostRatedSorted[row]], dtype=np.object)\n",
    "     for row in mostRatedSorted.index])\n",
    "mostRatedMovies[:10,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Most positively rated movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter movies rated with rating >=4.0. Then group by item, count the number of users and sort in descending order.\n",
    "positiveRated = train[train['rating']>=4.0].groupby('item_id')['user_id'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"b'Star Wars (1977)'\", 428],\n",
       "       [\"b'Fargo (1996)'\", 354],\n",
       "       [\"b'Return of the Jedi (1983)'\", 331],\n",
       "       [\"b'Raiders of the Lost Ark (1981)'\", 316],\n",
       "       [\"b'Silence of the Lambs, The (1991)'\", 310],\n",
       "       [\"b'Godfather, The (1972)'\", 298],\n",
       "       [\"b'Contact (1997)'\", 276],\n",
       "       [\"b'Toy Story (1995)'\", 275],\n",
       "       [\"b'Empire Strikes Back, The (1980)'\", 264],\n",
       "       [\"b'Pulp Fiction (1994)'\", 262]], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return a numpy array of np.array([id, title, frequency])\n",
    "positiveRatedMovies = np.array(\n",
    "    [np.array([row, unique_item_dict[row], \n",
    "               positiveRated[row]], dtype=np.object)\n",
    "     for row in positiveRated.index])\n",
    "positiveRatedMovies[:10,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Highest mean rating movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtaine the highest rated movies, with a minium number of users/ratings.\n",
    "min_ratings = 50\n",
    "\n",
    "# group the ratings by item and stack them in a list\n",
    "listRatedMovies=train.groupby('item_id')['rating'].apply(list).reset_index()\n",
    "\n",
    "# filter movies with a minimum number of ratings\n",
    "mask=listRatedMovies.rating.apply(lambda x: len(x) > min_ratings)\n",
    "filteredListRatedMovies = listRatedMovies[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[5, 4, 4, 4, 3, 1, 5, 5, 3, 5, 5, 5, 3, 5, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[3, 3, 2, 3, 5, 1, 3, 3, 4, 4, 3, 2, 2, 3, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[4, 2, 3, 4, 3, 2, 2, 1, 3, 3, 5, 3, 3, 3, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[3, 5, 4, 5, 5, 5, 3, 5, 4, 2, 4, 4, 3, 3, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[3, 1, 2, 3, 4, 4, 4, 3, 3, 2, 4, 3, 3, 4, 3, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                                             rating\n",
       "0        0  [5, 4, 4, 4, 3, 1, 5, 5, 3, 5, 5, 5, 3, 5, 4, ...\n",
       "1        1  [3, 3, 2, 3, 5, 1, 3, 3, 4, 4, 3, 2, 2, 3, 4, ...\n",
       "2        2  [4, 2, 3, 4, 3, 2, 2, 1, 3, 3, 5, 3, 3, 3, 2, ...\n",
       "3        3  [3, 5, 4, 5, 5, 5, 3, 5, 4, 2, 4, 4, 3, 3, 2, ...\n",
       "4        4  [3, 1, 2, 3, 4, 4, 4, 3, 3, 2, 4, 3, 3, 4, 3, ..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filteredListRatedMovies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the mean of the list of rating per movie\n",
    "meanMovies = filteredListRatedMovies.rating.apply(np.mean).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"b'Wallace & Gromit: The Best of Aardman Animation (1996)'\",\n",
       "        4.4915254237288131],\n",
       "       [\"b'Close Shave, A (1995)'\", 4.4807692307692308],\n",
       "       [\"b'Wrong Trousers, The (1993)'\", 4.4766355140186915],\n",
       "       ['b\"Schindler\\'s List (1993)\"', 4.4758364312267656],\n",
       "       [\"b'Casablanca (1942)'\", 4.4598214285714288],\n",
       "       [\"b'Shawshank Redemption, The (1994)'\", 4.4573643410852712],\n",
       "       [\"b'Usual Suspects, The (1995)'\", 4.3864541832669319],\n",
       "       [\"b'Rear Window (1954)'\", 4.3743589743589739],\n",
       "       [\"b'Star Wars (1977)'\", 4.3656565656565656],\n",
       "       [\"b'12 Angry Men (1957)'\", 4.3274336283185839]], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return a numpy array of np.array([id, title, frequency])\n",
    "meanRateMovies = np.array(\n",
    "    [np.array([row, unique_item_dict[row], \n",
    "               meanMovies[row]], dtype=np.object)\n",
    "     for row in meanMovies.index])\n",
    "\n",
    "meanRateMovies[:10,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class  = \"alert alert-info\"> \n",
    "** QUESTION **: set the value of *min_ratings* to 1, and re-run the cell. What happens now? Change this value\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class  = \"alert alert-info\"> \n",
    "** QUESTION **: Which method is better?? How to measure a recommender system? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class  = \"alert alert-info\"> \n",
    "** IMPORTANT QUESTION **: When might be useful to recommend popular items?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='metrics'></a>\n",
    "## 3. Metrics for recommender systems\n",
    "\n",
    "As we have seen, even with the simplest solution --aka, recommending popular items-- is difficult to known which technique performs better. For this, there are a number of metrics that allow one to measure the goodness of a recommender system. \n",
    "\n",
    "Metrics can be design for measuring the relevance or accuracy of a recommendation, but they can be created for evaluating the novelty of a recommendation, or its diversity. \n",
    "\n",
    "For now, we will focus on relevance and accuracy. Several metrics exist:\n",
    "* Accuracy: rmse, mae.\n",
    "* Not ranked: Recall@k, Precision@k.\n",
    "* With rank disccount: map@k, ndcg@k.\n",
    "* With rank ordering: mean percentile rank.\n",
    "\n",
    "We will be definiing some of them whitin this class. For the moment, let's talk about precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Precision and recall\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg\" alt=\"Precision and Recall in IR\" style=\"float: right; width: 300px\"/>\n",
    "\n",
    "The concept of precision and recall comes form the world of information retrieval, have a look at the wikipedia:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "\n",
    "From this entry:\n",
    "\n",
    " * \"**precision** (also called positive predictive value) is the fraction of retrieved instances that are relevant\".\n",
    " * \"**recall** (also known as sensitivity) is the fraction of relevant instances that are retrieved\".\n",
    "\n",
    "<br />\n",
    "<div class  = \"alert alert-info\"> \n",
    "** QUESTION **: how do we know if some movie, unknown to the user, is relevant?\n",
    "</div>\n",
    "\n",
    "In other words, we cannot measure a false positive --something recommended that was not relevant--. In this regard, only recall-oriented metrics have an actual meaning in RS. Nonetheless, its common practice to define both metrics in RS as follows:\n",
    " \n",
    "### $$\\mathrm{recall}@N = \\frac{\\sum_{k=1}^N rel(k)}{\\sum_{i\\in \\mathcal{I}_u} 1}$$\n",
    "### $$\\mathrm{precision}@N = \\frac{\\sum_{k=1}^N rel(k)}{N}$$\n",
    "\n",
    "Here, $\\mathcal{I}_u$ is the set of items adopted by user $u$, and $rel(k)$ is the relevance of a recommendation at position k in the list of recommendations. For ratings, the relevance could be defined as those movies rated above a certain threshold, e.g. $r_{ui}>4.0$. \n",
    "\n",
    "**Important to note: since precision is pretty much the same as recall in RS, metrcis usch as the *area under the ROC curve* doesn't have any meaning!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "As an example, consider a user that watched the following films:\n",
    "<br /><br />\n",
    "'Designated Mourner, The (1997)'\n",
    "<br />\n",
    "'Money Talks (1997)'\n",
    "<br />\n",
    "'Madame Butterfly (1995)'\n",
    "<br />\n",
    "'Batman Forever (1995)'\n",
    "<br /><br />\n",
    "The recommended items were: \n",
    "<br /><br />\n",
    "'Batman (1989)' \n",
    "<br />\n",
    "'Madame Butterfly (1995)'\n",
    "<br /><br />\n",
    "**What would be the recall and precision @1? and @2?**\n",
    "<br />\n",
    "**What do you think of recommending Batman? Is a bad or a good recommendation?**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please notice that there isn't any actual difference between precision and recall in the context of RS: both measure the relevance of the recommendations, and tell nothing about items recommended that haven't been adopted by the user. Thus, it make sense to define a normalized recall as:\n",
    "\n",
    "### $$\\mathrm{recall}@N = \\frac{\\sum_{i=1}^N rel_i}{\\mathrm{min}(N, \\sum_{i\\in \\mathcal{I}_u} 1})$$\n",
    "\n",
    "This way, results are normalized to 1 always."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "**Exercise** Implement the above definition of recall\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall_at_n(N, seen, recommended):\n",
    "    \"\"\"\n",
    "    :param N: number of recommendations\n",
    "    :param seen: list of movies seen by user\n",
    "    :param recommended: list of movies recommended\n",
    "    \n",
    "    :return the recall\n",
    "    \"\"\"\n",
    "    intersection = len(set(seen) & set(recommended[:N]))\n",
    "    return intersection / float(len(seen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seen = ['Designated Mourner, The (1997)', 'Money Talks (1997)', 'Madame Butterfly (1995)', 'Batman Forever (1995)']\n",
    "recommended = ['Batman (1989)', 'Madame Butterfly (1995)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_at_n(1, seen, recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_at_n(2, seen, recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.25\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "# Check it's well normalized\n",
    "print(recall_at_n(3, seen, recommended))\n",
    "print(recall_at_n(10, seen, recommended))\n",
    "print(recall_at_n(100, seen, recommended))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, use this implementation to measure the efficiency of the popularity baselines in the test set. Use the top-5 movies, for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mostRatedMovies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-2ac407b03602>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmostRatedMovies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mostRatedMovies' is not defined"
     ]
    }
   ],
   "source": [
    "mostRatedMovies[:5,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"b'Star Wars (1977)'\", 428],\n",
       "       [\"b'Fargo (1996)'\", 354],\n",
       "       [\"b'Return of the Jedi (1983)'\", 331],\n",
       "       [\"b'Raiders of the Lost Ark (1981)'\", 316],\n",
       "       [\"b'Silence of the Lambs, The (1991)'\", 310]], dtype=object)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positiveRatedMovies[:5,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"b'Wallace & Gromit: The Best of Aardman Animation (1996)'\",\n",
       "        4.4915254237288131],\n",
       "       [\"b'Close Shave, A (1995)'\", 4.4807692307692308],\n",
       "       [\"b'Wrong Trousers, The (1993)'\", 4.4766355140186915],\n",
       "       ['b\"Schindler\\'s List (1993)\"', 4.4758364312267656],\n",
       "       [\"b'Casablanca (1942)'\", 4.4598214285714288]], dtype=object)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanRateMovies[:5,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testUsersGrouped = (test[test.rating>=4.0]\n",
    "                    .groupby('user_id')['item_id']\n",
    "                    .apply(list)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topN = 30\n",
    "# calculate the average recall across all users\n",
    "<fill in>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<fill in>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Mean Averaged Precision (MAP)\n",
    "\n",
    "Previous metrics did not account for the ranking of the recommendation, i.e. the relative position of a movie within the sorted list of recommendations. **But orders matters!** Metrics like MAP, MRR or NDCG try to tackle down this problem. \n",
    "\n",
    "From the blog *http://fastml.com/what-you-wanted-to-know-about-mean-average-precision/*:\n",
    "\n",
    "> Here’s another way to understand average precision. Wikipedia says AP is used to score document retrieval. You can think of it this way: you type something in Google and it shows you 10 results. It’s probably best if all of them were relevant. If only some are relevant, say five of them, then it’s much better if the relevant ones are shown first. It would be bad if first five were irrelevant and good ones only started from sixth, wouldn’t it? AP score reflects this.\n",
    "\n",
    "Implementation taken from:\n",
    "\n",
    "https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Precision \n",
    "\n",
    "The Average Precision is definied as:\n",
    "\n",
    "### $$\\mathrm{AP}@N = \\frac{\\sum_{k=1}^N P(k) \\times rel(k)}{\\mathrm{min}(N, \\sum_{i\\in \\mathcal{I}_u} 1)}$$\n",
    "\n",
    "where $P(k)$ is the precision at cut-off in the item list, i.e. the ratio of the number of recommended items adopted, up to the position k, over the number k. Thus:\n",
    "\n",
    "### $$\\mathrm{AP}@N = \\frac{\\sum_{k=1}^N \\left(\\sum_{i=1}^k rel(i)\\right)/k \\times rel(k)}{\\mathrm{min}(N, \\sum_{i\\in \\mathcal{I}_u} 1)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "Following the example above, consider a user that watched the following films:\n",
    "<br /><br />\n",
    "'Designated Mourner, The (1997)'\n",
    "<br />\n",
    "'Money Talks (1997)'\n",
    "<br />\n",
    "'Madame Butterfly (1995)'\n",
    "<br />\n",
    "'Batman Forever (1995)'\n",
    "<br /><br />\n",
    "The recommended items were: \n",
    "<br /><br />\n",
    "'Batman (1989)' \n",
    "<br />\n",
    "'Madame Butterfly (1995)'\n",
    "<br /><br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**Calculate AP@1**\n",
    "<br /><br />\n",
    "First, *rel(1)=0*, because Batman was not viewed. Also, *P(1) = 0*. Thus, AP@1=0.\n",
    "<br />\n",
    "**Calculate AP@2**\n",
    "<br /><br />\n",
    "As before, *rel(1)=0*, so the first term does not contribute. For the second term, *rel(2)=1*, so that *P(2)=0.5*. The numerator is hence:\n",
    "<br /><br />\n",
    "$P(1)*rel(1)+P(2)*rel(2)=0*0+0.5*1$\n",
    "<br /><br />\n",
    "For the denominator, $N=2$ and $\\sum_{i\\in \\mathcal{I}_u} 1)=4$, thus:\n",
    "<br /><br />\n",
    "AP@2 = 0.5/2 = 0.25\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now implement it =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    \n",
    "    :param actual : A list of elements that are to be predicted (order doesn't matter)\n",
    "    :param predicted : A list of predicted elements (order does matter)\n",
    "    :param k: The maximum number of predicted elements\n",
    "    \n",
    "    :return The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    predicted = predicted[:k] # top-k predictions\n",
    "    \n",
    "    score = 0.0 # This will store the numerator\n",
    "    num_hits = 0.0 # This will store the sum of rel(i)\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits/(i+1.0)\n",
    "\n",
    "    return score / min(len(actual), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seen = ['Designated Mourner, The (1997)', 'Money Talks (1997)', 'Madame Butterfly (1995)', 'Batman Forever (1995)']\n",
    "recommended = ['Batman (1989)', 'Madame Butterfly (1995)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apk(seen, recommended, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apk(seen, recommended, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apk(seen, recommended, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP\n",
    "\n",
    "Mean avergae precision is nothing else than the AP averaged across users ;)\n",
    "\n",
    "Apply it to popularity baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testUsersGrouped = (test[test.rating>=4.0]\n",
    "                    .groupby('user_id')['item_id']\n",
    "                    .apply(list)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topN = 30\n",
    "<fill in>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<fill in>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://courses.edx.org/c4x/BerkeleyX/CS100.1x/asset/Collaborative_filtering.gif\" alt=\"collaborative filtering\" style=\"float: right; width: 300px\"/>\n",
    "\n",
    "## 4. Collaborative Filtering <a id='cf'></a>\n",
    "\n",
    "Perhaps, one of the most succesful techniques for making personalized recommendations are the so called *collaborative filtering* (CF) algorithms. CF is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue X than to have the opinion on X of a person chosen randomly. \n",
    "\n",
    "The image at the right (from Wikipedia) shows an example of user's preference prediction using collaborative filtering. At first, people rate different items (like videos, images, games). After that, the system is making predictions about a user's rating for an item, which the user has not rated yet. These predictions are built upon the existing ratings of other users, who have similar ratings with the active user. For instance, in the image at the right the system has made a prediction, that the active user will not like the video.\n",
    "\n",
    "In this part we will see three kinds of CF, of increasing complexity:\n",
    "\n",
    "4.1 [CF with co-occurrence](#copurchase)\n",
    "\n",
    "4.2 [Memory-based CF](#memory-base)\n",
    "\n",
    "4.3 [Model-based CF](#model-base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='copurchase'></a>\n",
    "## 4.1 Co-occurrence Matrix\n",
    "\n",
    "The idea is to recommend movies similar to the movies already seen by a user. A measurement of similarity among items is obtained from the co-occurrence matrix. This is nothing else than the adjacency matrix of the graph of items created by users!!!\n",
    "\n",
    "<table border=\"0\" style=\"width:825px;border:0px;\">\n",
    "<tr>\n",
    "    <td> \n",
    "        <img src=\"https://lucidworks.com/wp-content/uploads/2015/08/Les-Miserables-Co-Occurrence.png\" style=\"width: 500px\"/>\n",
    "    </td>\n",
    "    <td> \n",
    "        <img src=\"https://lucidworks.com/wp-content/uploads/2015/08/midnight-club-graph.png\" style=\"width: 400px\"/>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dictionary of movies per user\n",
    "moviesPerUser = (train[train.rating>=4]\n",
    "                 .groupby('user_id')['item_id']\n",
    "                 .apply(np.array)\n",
    "                 .to_dict()\n",
    "                 )\n",
    "moviesPerUser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dictionary of movies per user\n",
    "moviesPerUser = (train[train.rating>=4]\n",
    "                 .groupby('user_id')['item_id']\n",
    "                 .apply(np.array)\n",
    "                 .to_dict()\n",
    "                 )\n",
    "\n",
    "# calculate the number of items in train\n",
    "n_items = len(unique_item_dict.keys())\n",
    "\n",
    "# co-ocurrance matrix will have shape=[n_items,n_items]\n",
    "coMatrix = np.zeros((n_items, n_items)) # co-occurrence matrix\n",
    "for user,movies in moviesPerUser.items():\n",
    "    <fill in>\n",
    "\n",
    "coMatrix = np.zeros((n_items, n_items)) # co-occurrence matrix                \n",
    "for user,movies in moviesPerUser.items():\n",
    "    <fill in>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize the matrix\n",
    "plt.matshow(coMatrix, fignum=1000, cmap=plt.cm.binary)\n",
    "plt.gcf().set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "**QUESTION:** Can you think of a better way of visualizaing this matrix? Try to rescale it, or to rearrenge it follwoing some criteria (for instance, popularity!).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mostRatedMovies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popular_indexing = <fill in>\n",
    "coMatrix_sorted = coMatrix[:,popular_indexing]\n",
    "plt.matshow(<fill in>, fignum=1000, cmap=plt.cm.binary)\n",
    "plt.gcf().set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# better plot it in log scale!\n",
    "<fill in>\n",
    "plt.gcf().set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Making predictions using the co-occurrence matrix\n",
    "\n",
    "This kind of recommendations, based on item similarity, provide a measure of the closeness of one item to another. In order to make a recommendation for a user, we have to proceed as follows:\n",
    "\n",
    "* First, define a function that returns the top-N closest items to a given one.\n",
    "* Then, for a list of items adopted by a specific user, select the top-N items from the lists of top-N closest items to each adopted item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def co_occurrance_similarity(item_id, coocurrance, ntop=10):\n",
    "    \"\"\"\n",
    "    Returns the top-N most similar items to a given one, based on the coocurrance matrix\n",
    "    \n",
    "    :param item_id: id of input item\n",
    "    :param cooccurrance: 2-dim numpy array with the co-occurance matrix\n",
    "    :param ntop: number of items to be retrieved\n",
    "    \n",
    "    :return top-N most similar items to the given item_id\n",
    "    \"\"\"\n",
    "    similarItems = <fill in>\n",
    "    # return indeces of most similar items in descendign order\n",
    "    mostSimilar = <fill in>\n",
    "    # remove the first element, as it is the item itslef\n",
    "    mostSimilar = <fill in>\n",
    "    \n",
    "    # return a numpy array with the index and the value of the most similar items\n",
    "    return <fill in>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queryMovieId = 23\n",
    "Ntop = 5\n",
    "print('For item \"%s\" top-%s recommendations are:' % (unique_item_dict[queryMovieId], Ntop))\n",
    "\n",
    "similarItems = co_occurrance_similarity(queryMovieId, coMatrix, Ntop)\n",
    "# let's print out the first Ntop recommendations\n",
    "for r in similarItems:\n",
    "    print(unique_item_dict[r[0]], r[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let use this function to make recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def co_occurrance_recommendation(items_id, cooccurrance, ntop=10):\n",
    "    \"\"\"\n",
    "    Obtain the list of ntop recommendations based on a list of items (user history of views)\n",
    "    \n",
    "    :param items_id: list of items ids\n",
    "    :param coocurrence: co-ocurrence matrix (numpy 2-dim array)\n",
    "    :param ntop: top-K items to be retrieved\n",
    "    \n",
    "    :return list of ntop items recommended\n",
    "    \"\"\"\n",
    "    # put together all the similar items and its value\n",
    "    list_sim_items = <fill in>\n",
    "    # sort by value in descending order\n",
    "    sorted_list = <fill in>\n",
    "    # We have to remove duplicates\n",
    "    unique_items = <fill in>\n",
    "    return unique_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get users in train with their movies\n",
    "trainUsersGrouped = <fill in>\n",
    "trainUsersGrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the recommendation for a single user\n",
    "co_occurrance_recommendation(trainUsersGrouped[1], coMatrix, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ntop = 10\n",
    "# Do the same for all users using the apply method\n",
    "predictions = trainUsersGrouped.<fill in>\n",
    "predictions[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (seen, recom) in zip(testUsersGrouped, predictions)[:3]:\n",
    "    print(\"*\"*6)\n",
    "    print(\"Seen items: \")\n",
    "    print([unique_item_dict[i] for i in seen])\n",
    "    print(\"Recommended items: \")\n",
    "    print([unique_item_dict[i] for i in recom])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute the recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topN = 30\n",
    "# get predictions\n",
    "predictions = trainUsersGrouped.<fill in>\n",
    "\n",
    "# join the list of movies seen by users and their predicitons\n",
    "targets_predictions = <fill in>\n",
    "# average recall across all users\n",
    "recall = <fill in>\n",
    "# average map across all users\n",
    "map_ = <fill in>\n",
    "\n",
    "print(\"Recall=%.3f; MAP=%.3f\" %(recall, map_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\">\n",
    "Compare this results to those obtained with the popularity model. Was it so bad?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Oher distances\n",
    "\n",
    "So far, we have defined the *closeness* of two items as the number of users shared. However, it would make make sense to define it relative the total number of users that have watch a movie. This can be done with the [Jaccard similarity index](https://en.wikipedia.org/wiki/Jaccard_index):\n",
    "\n",
    "$$J(i,j)=\\frac{|i\\cap j|}{|i|+|j|-|i\\cap j|}\\in [0,1]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "Build the Jaccard similarity matrix from the co-occurrance matrix. Notice that $CoM(i,j) = |i\\cap j|$ and $CoM(i,i) = |i|$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jaccard = np.zeros((n_items, n_items)) # Jaccard similarity matrix\n",
    "for i, row in enumerate(coMatrix):\n",
    "    if row[i]==0:\n",
    "        <fill in>\n",
    "    else:\n",
    "        <fill in>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize the matrix\n",
    "plt.matshow(jaccard, fignum=1000, cmap=plt.cm.binary)\n",
    "plt.gcf().set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popular_indexing = <fill in>\n",
    "jaccard_sorted = <fill in>\n",
    "plt.matshow(<fill in>, fignum=1000, cmap=plt.cm.binary)\n",
    "plt.gcf().set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queryMovieId = 23\n",
    "Ntop = 5\n",
    "print('For item \"%s\" top-%s similar items are:' % (unique_item_dict[queryMovieId], Ntop))\n",
    "\n",
    "similarItems = <fill in>\n",
    "# let's print out the first Ntop recommendations\n",
    "for r in similarItems:\n",
    "    print(unique_item_dict[r[0]], r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ntop = 10\n",
    "# Calculate the predictoins with Jaccard\n",
    "predictions = trainUsersGrouped.<fill in>\n",
    "predictions[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (seen, recom) in zip(testUsersGrouped, predictions)[:3]:\n",
    "    print(\"*\"*6)\n",
    "    print(\"Seen items: \")\n",
    "    print([unique_item_dict[i] for i in seen])\n",
    "    print(\"Recommended items: \")\n",
    "    print([unique_item_dict[i] for i in recom])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topN = 30\n",
    "# get predictions\n",
    "predictions = trainUsersGrouped.<fill in>\n",
    "\n",
    "\n",
    "# join the list of movies seen by users and their predicitons\n",
    "targets_predictions = <fill in>\n",
    "# average recall across all users\n",
    "recall = <fill in>\n",
    "# average map across all users\n",
    "map_ = <fill in>\n",
    "\n",
    "print(\"Recall=%.3f; MAP=%.3f\" %(recall, map_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\">\n",
    "** QUESTION **: Can you think of any other way of using the graph of items?\n",
    "Some hints:\n",
    "\n",
    "<br></br>\n",
    "Page Rank\n",
    "<br></br>\n",
    "Shortest-path\n",
    "<br></br>\n",
    "Clustering methods: eigenvalues, spectral mehtods, etc.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='memory-base'></a>\n",
    "## 4.2. Memory-Based Collaborative Filtering (CF)\n",
    "\n",
    "Although the methods developed so far return a list of recommended items, they cannot be used to make an actual prediction regarding the rating. A quite different approach would be to calculate the unknown rating, $r_{ui}$, as the averaged of some other ratings, thta are somehow close to either the user or the item in question. \n",
    "\n",
    "Thus, one approach is to take\n",
    "\n",
    "### $$r_{u,i} = \\frac{1}{K}\\sum_{j\\in\\mathcal{I}'} \\mathrm{sim}(i,j) r_{u,j},$$\n",
    "\n",
    "where items $j\\in\\mathcal{I}'$ are taken from the set of $K$ closest items to $i$, or from the whole dataset. This is known as **item-item collaborative filtering**, and can be interpreted as *“users who liked this movie also liked …”*. See Amazon famous patent: https://www.google.com/patents/US7113917. Basically, this technique will take an item, find users who liked that item, and find other items that those users or similar users also liked. \n",
    "\n",
    "Similarly, one can define a **user-user filtering** where predictions are made as\n",
    "\n",
    "### $$r_{u,i} = \\frac{1}{K} \\sum_{v\\in\\mathcal{U}'} \\mathrm{sim}(u,v) r_{v,i}.$$\n",
    "\n",
    "<img src=\"https://soundsuggest.files.wordpress.com/2013/06/utility_matrix.png\" alt=\"utility matrix\" style=\"float: right; width: 400px\"/>\n",
    "\n",
    "In this case, the recommendation would be more like *“users who are similar to you also liked …”*. Both techniques are part of the broad familiy of **Memory-Based Collaborative Filtering** approaches, or neighborhood-based algorithms.\n",
    "\n",
    "The similarity among users or items can be calculated in a variety of forms: Pearson's correlation, cosine distance, etc. Here we will use the cosine distance. For this, we will first create the utility user-item matrix. \n",
    "\n",
    "The utility matrix is a dense representation of the user-item intearction. We have been using the *long* format, where missing entries are obviated; now, we will use the *wide* format, i.e. the matrix representation (see the figure on the right). \n",
    "\n",
    "<br></br>\n",
    "<div class = \"alert alert-info\">\n",
    "** NOTE **: Long and wide formats have its benefits and drawbacks. Can you think of some of them?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.values[:,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the train and test datasets in wide format (i.e., like a matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uMatrixTraining = np.zeros((n_users, n_items)) # utility matrix\n",
    "for row in train.values[:,0:3]:\n",
    "    # Note ids start at 1\n",
    "    <fill in>\n",
    "    \n",
    "uMatrixTesting = np.zeros((n_users, n_items)) # utility matrix\n",
    "for row in test.values[:,0:3]:\n",
    "    # Note ids start at 1\n",
    "    <fill in>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a similarity measure: cosine similarity\n",
    "\n",
    "### $$\\mathrm{sim}({\\bf a},{\\bf b})=\\frac{{\\bf a}\\cdot{\\bf b}}{\\sqrt{{\\bf a}\\cdot{\\bf a}}\\sqrt{{\\bf  b}\\cdot{\\bf b}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosineSimilarity(ratings, kind='user', epsilon=1e-9):\n",
    "    \"\"\"\n",
    "    Calculate the cosine distance along the row (columns) of a matrix for users (items)\n",
    "    \n",
    "    :param ratings: a n_user X n_items matrix\n",
    "    :param kind: string indicating whether we are in mode 'user' or 'item'\n",
    "    :param epsilon: a small value to avoid dividing by zero (optional, defaults to 1e-9)\n",
    "    \n",
    "    :return a square matrix with the similarities\n",
    "    \"\"\"\n",
    "    # epsilon -> small number for handling dived-by-zero errors\n",
    "    if kind == 'user':\n",
    "        sim = <fill in>\n",
    "    elif kind == 'item':\n",
    "        sim = <fill in>\n",
    "    norms = <fill in>\n",
    "    return sim / norms / norms.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. User-user CF\n",
    "\n",
    "*“Users who are similar to you also liked …”*\n",
    "\n",
    "Consider user $x$:\n",
    "\n",
    "1. Find other users whose ratings are “similar” to $x$’s ratings, i.e. calculate the similarity among users\n",
    "2. Estimate missing ratings based on ratings of similar users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we use cosine similarity\n",
    "userSimilarity = cosineSimilarity(uMatrixTraining, kind='user')\n",
    "userSimilarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userItemCFpredictions = <fill in>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Be careful: take a look at the values\n",
    "np.max(userItemCFpredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. Item-Item CF\n",
    "\n",
    "*“Users who liked this movie also liked …”*\n",
    "\n",
    "Consider item $i$:\n",
    "\n",
    "1. For item $i$, find other similar items, i.e. calculate the similarity among items\n",
    "2. Estimate rating for item $i$ based on ratings for similar items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we use cosine similarity\n",
    "itemSimilarity = cosineSimilarity(uMatrixTraining, kind='item')\n",
    "print(itemSimilarity.shape)\n",
    "itemItemCFpredictions = uMatrixTraining.dot(itemSimilarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "**QUESTION:** Is averaging across all users or items computationally efficent? \n",
    "<br></br>\n",
    "<br></br>\n",
    "This is why nearest-neighbourghs methods (**KNN**) exists\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Show some recommendations\n",
    "\n",
    "In case of item-item CF, the recommendation is pretty much the same as with the co-occurence matrix. It's also quite simple to find similar items to a given one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Find movies similar to a given one using the item-item similarity matrix.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queryMovieId = 720\n",
    "print(\"Select item is '%s'\" % unique_item_dict[queryMovieId])\n",
    "\n",
    "\n",
    "queryAnswer = <fill in>\n",
    "queryAnswer = <fill in> #descending order\n",
    "queryAnswer = <fill in>  # remove first item (itself)\n",
    "\n",
    "# let's print out the most similar items\n",
    "print(\"Most similar movies are:\")\n",
    "printAnswer = queryAnswer[0:10]\n",
    "for answerId in printAnswer:\n",
    "    print unique_item_dict[answerId]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Calculate the recommendations obtained with the item-item CF model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove relevant items seen in train from our prediction:\n",
    "itemItemCFpredictions[uMatrixTraining>=4.0] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for u in np.random.randint(0, n_users, 3):\n",
    "    print(\"*\"*6)\n",
    "    print(\"User %s\" % u)\n",
    "    print(\"Seen items: \")\n",
    "    seen = uMatrixTesting[u,:]\n",
    "    print([unique_item_dict[i] for i,r in enumerate(seen) if r>4.0])\n",
    "    print(\"Recommended items: \")\n",
    "    recom = itemItemCFpredictions[u,:]\n",
    "    recom = np.argsort(recom)[::-1][:10]\n",
    "    print([unique_item_dict[i] for i in recom])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Do the same with the user-user CF model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 Measure the recommendations\n",
    "\n",
    "Since we are predicting ratings, it might make sense to introduce a metric that accounts for this. In particular, the **Root Mean Square Error (RMSE)** is typically used for this purpose. \n",
    "\n",
    "### $$\\mathrm{RMSE}=\\sqrt{\\frac{1}{n_{\\mathrm{users}}n_{\\mathrm{items}}}\\sum_{u,i}\\left(r_{u,i}-\\hat{r}_{u,i}\\right)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "    \"\"\"\n",
    "    Return the Root Mean Squared Error of the prediction\n",
    "    \n",
    "    :param prediction: a 2-dim numpy array with the predictions\n",
    "    :param ground_truth: a 2-dim numpy array with the known ratings\n",
    "    \n",
    "    :return the RMSE\n",
    "    \"\"\"\n",
    "    return sqrt(np.mean(np.power(prediction-ground_truth, 2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('User-based CF RMSE=%.3f' %rmse(userItemCFpredictions, uMatrixTesting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Item-based CF RMSE=%.3f' %rmse(itemItemCFpredictions, uMatrixTesting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-danger\">\n",
    "**IMPORTANT TO NOTE**: RMSE was used in the RecSys community for many years to measure the accuracy \n",
    "of recommendations. However, it was demonstrated that high accuracy in predicting rating does not imply a good\n",
    "ranked list!!    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate ranking metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ntop = 30\n",
    "userItemCFpredictions_sorted = <fill in>\n",
    "\n",
    "# recall\n",
    "np.mean([recall_at_n(Ntop,seen, recom) \n",
    "         for (seen, recom) in <fill in>])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ntop = 30\n",
    "itemItemCFpredictions_sorted = <fill in>\n",
    "\n",
    "np.mean([recall_at_n(Ntop,seen, recom) \n",
    "         for (seen, recom) in <fill in>])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model-base'></a>\n",
    "## 4.3. Model-based CF or Latent factor models\n",
    "There are several model-based CF: from matrix factorizations to bayesian models, neural netwroks, etc. In all of them, we try to extract latent factors (vectors) that model user and item behaviour. Then, we use this latent features to make a prediction:\n",
    "\n",
    "## $$r_{u,i} \\approx {\\bf f}_u^T\\cdot{\\bf f}_i$$\n",
    "\n",
    "The underlying assumption is that both users and items *live* in the same latent space, and that we can unravel such space. \n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Tunca_Dogan/publication/235913413/figure/fig3/AS:299678856957952@1448460415040/The-distribution-of-the-points-in-the-Swiss-roll-dataset-in-3-D-space.png\" alt=\"swiss roll\" style=\"float: center; width: 300px\"/>\n",
    "\n",
    "\n",
    "Here we will use a couple of linear Matrix Factorization (MF) models:\n",
    "\n",
    "* Singular Value decomposition (SVD)\n",
    "* Alternating Least Squares (ALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Singular value decomposition\n",
    "\n",
    "The main idea is to reduce the dimensionality of the input space. This is pretty much the same as Eigen-decomposition or Principal Component Analysis (PCA)-\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f5/GaussianScatterPCA.svg/220px-GaussianScatterPCA.svg.png\n",
    "\" alt=\"dimensionaly reducion\" style=\"float: center; width: 500px\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# look at the help!!!\n",
    "svds??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get SVD components from train matrix. Choose k.\n",
    "k=20\n",
    "u, s, vt = svds(uMatrixTraining, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# take a look at the different matrices\n",
    "\n",
    "# U should be an orthogonal matrix with the left singular vectors as columns\n",
    "print(u.shape)\n",
    "# Check U is orthogonal\n",
    "print(rmse(np.dot(u.T,u), np.identity(k)))\n",
    "\n",
    "# Same with V\n",
    "print(vt.shape)\n",
    "print(rmse(np.dot(vt,vt.T), np.identity(k)))\n",
    "\n",
    "# s is a vector with the singular values\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the recommendations\n",
    "\n",
    "We will reconstruct the utility matrix R as follows:\n",
    "\n",
    "### $$M\\approx U\\mathrm{diag}(s)V^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a diagonal matrix with the eigenvalues\n",
    "s_diag_matrix = np.diag(s)\n",
    "\n",
    "# make the prediction\n",
    "svdPredictions = np.dot(np.dot(u, s_diag_matrix), vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check the dimensions are correct\n",
    "print(svdPredictions.shape)\n",
    "print(uMatrixTesting.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "\n",
    "* RMSE\n",
    "* Recall@30\n",
    "* MAP@30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('SVD RMSE=%.3f' % rmse(svdPredictions, uMatrixTesting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recall\n",
    "np.mean([recall_at_n(<fill in>) for target, rec in <fill in>])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-danger\">\n",
    "**IMPORTANT TO NOTE**: RMSE was used in the RecSys community for many years to measure the accuracy \n",
    "of recommendations. However, it was demonstrated that high accuracy in predicting rating does not imply a good\n",
    "ranked list!!    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Alternating Least Squares (ALS)\n",
    "\n",
    "SVD can be very slow and computationally expensive. Besides, when addressing only the relatively few known entries we are highly prone to overfitting.\n",
    "\n",
    "An scalable alternative to SVD is ALS, which can include regularization terms to prevent overfitting. We will rename our variable to make them more similar to the ALS notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = uMatrixTraining\n",
    "T = uMatrixTesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implicit vs Explicit feedback\n",
    "Now we define a “selector” matrix $I$ for the training utility matrix $R$, which will contain 0 if the rating matrix has no rating entry, and 1 if the rating matrix contains an entry. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Index matrix for training data\n",
    "I = R.copy()\n",
    "I[I > 3] = 1\n",
    "I[I == 0] = 0\n",
    "\n",
    "# Index matrix for test data\n",
    "I2 = T.copy()\n",
    "I2[I2 > 3] = 1\n",
    "I2[I2 == 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS algorithm\n",
    "\n",
    "The ALS algorithm aims to estimate two unknown matrices which, when multiplied together, yield the rating matrix. The loss function you will use is the well-known sum of squared errors. The second term is for regularisation to prevent overfitting\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?\\underset{Q*&space;,&space;P*}{min}\\sum_{(u,i)\\epsilon&space;K&space;}(r_{ui}-P_u^TQ_i)^2&plus;\\lambda(\\left&space;\\|&space;Q_i&space;\\right&space;\\|^2&space;&plus;&space;\\left&space;\\|&space;P_u&space;\\right&space;\\|^2)$&space;&space;$\" title=\"\\underset{q* , p*}{min}\\sum_{(u,i)\\epsilon K }(r_{ui}-q_i^Tp_u)^2+\\lambda(\\left \\| q_i \\right \\|^2 + \\left \\| p_u \\right \\|^2)\" />\n",
    "\n",
    "The Alternating Least Squares algorithm does this by first randomly filling the users matrix with values and then optimizing the value of the movies such that the error is minimized.  Then, it holds the movies matrix constant and optimizes the value of the user's matrix.  This alternation between which matrix to optimize is the reason for the \"alternating\" in the name. \n",
    "\n",
    "<img alt=\"factorization\" src=\"http://spark-mooc.github.io/web-assets/images/matrix_factorization.png\" style=\"width: 885px\"/>\n",
    "<br clear=\"all\"/>\n",
    "\n",
    "This optimization is what's being shown on the right in the image above.  Given a fixed set of user factors (i.e., values in the users matrix), we use the known ratings to find the best values for the movie factors using the optimization written at the bottom of the figure.  Then we \"alternate\" and pick the best user factors given fixed movie factors.\n",
    "\n",
    "It must be noticed that this is another way of reducing the dimensionality of the input matrix (like PCA, or more generally, SVD). This has important consequences:\n",
    "\n",
    "* ### Our decomposition is linear. We won't be able to catch non-linear relationships among users and items.\n",
    "* ### As in PCA or SVD, our features will correspond to directions of maximum variance in the data. Thus, the first feature will catch most of this variation, the second, a little bit more, and so on. It implies that the error in the reconstruction will not decrease dramatically when using more features!!! Keep this in mind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alsRmse(I,R,Q,P):\n",
    "    return np.sqrt(np.sum((I * (R - np.dot(P.T,Q)))**2)/len(R[R > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Algorithm free parameters\n",
    "lmbda = 0.1     # Regularisation weight\n",
    "k = 20          # Dimensionality of latent feature space\n",
    "m, n = R.shape  # Number of users and items\n",
    "n_epochs = 15   # Number of epochs\n",
    "\n",
    "# Initialization\n",
    "P = 3 * np.random.rand(k,m) # Latent user feature matrix\n",
    "Q = 3 * np.random.rand(k,n) # Latent movie feature matrix\n",
    "Q[0,:] = R[R != 0].mean(axis=0) # Avg. rating for each movie\n",
    "E = np.eye(k) # (k x k)-dimensional idendity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "# Repeat until convergence\n",
    "for epoch in range(n_epochs):\n",
    "    # Fix Q and estimate P\n",
    "    for i, Ii in enumerate(I):\n",
    "        nui = np.count_nonzero(Ii) # Number of items user i has rated\n",
    "        if (nui == 0): nui = 1 # Be aware of zero counts!\n",
    "    \n",
    "        # Least squares solution\n",
    "        Ai = np.dot(Q, np.dot(np.diag(Ii), Q.T)) + lmbda * nui * E\n",
    "        Vi = np.dot(Q, np.dot(np.diag(Ii), R[i].T))\n",
    "        P[:,i] = np.linalg.solve(Ai,Vi)\n",
    "        \n",
    "    # Fix P and estimate Q\n",
    "    for j, Ij in enumerate(I.T):\n",
    "        nmj = np.count_nonzero(Ij) # Number of users that rated item j\n",
    "        if (nmj == 0): nmj = 1 # Be aware of zero counts!\n",
    "        \n",
    "        # Least squares solution\n",
    "        Aj = np.dot(P, np.dot(np.diag(Ij), P.T)) + lmbda * nmj * E\n",
    "        Vj = np.dot(P, np.dot(np.diag(Ij), R[:,j]))\n",
    "        Q[:,j] = np.linalg.solve(Aj,Vj)\n",
    "    \n",
    "    train_rmse = alsRmse(I,R,Q,P)\n",
    "    test_rmse = alsRmse(I2,T,Q,P)\n",
    "    train_errors.append(train_rmse)\n",
    "    test_errors.append(test_rmse)\n",
    "    \n",
    "    print \"[Epoch %d/%d] train error: %f, test error: %f\" \\\n",
    "    %(epoch+1, n_epochs, train_rmse, test_rmse)\n",
    "    \n",
    "print \"Algorithm converged\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check performance by plotting train and test errors\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(n_epochs), train_errors, marker='o', label='Training Data');\n",
    "plt.plot(range(n_epochs), test_errors, marker='v', label='Test Data');\n",
    "plt.title('ALS-WR Learning Curve')\n",
    "plt.xlabel('Number of Epochs');\n",
    "plt.ylabel('RMSE');\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alsPredictions = np.dot(P.T,Q)\n",
    "\n",
    "svdPredictions = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "print 'ALS CF RMSE: ' + str(rmse(alsPredictions, uMatrixTesting))\n",
    "print 'SVD CF RMSE: ' + str(rmse(svdPredictions, uMatrixTesting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queryAnswer = alsPredictions[queryUser,noWatchedMovies]\n",
    "queryAnswer = noWatchedMovies[np.argsort(queryAnswer)[::-1]] #descending order\n",
    "\n",
    "print 'so, it is expected he/she also likes ... '\n",
    "print ' '\n",
    "\n",
    "printAnswer = queryAnswer[0:11]\n",
    "for answerId in printAnswer:\n",
    "    print idx_to_movie[answerId]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class = \"alert alert-info\">\n",
    "What about MAP and Recall metrics?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class = \"alert alert-info\">\n",
    "Try different dimensions for the latent feature space? what do you observe?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercises'></a>\n",
    "## 4. Exercises (advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**E1:** Implement centered cosine similarity metric in [Section 2](#cf)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**E2:** Implement global baseline biased in [Section 2](#cf): $b_{ui} = \\mu + b_u + b_i$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**E3:** Implement k-neighbors in [Section 2](#cf)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at http://infolab.stanford.edu/~ullman/mmds/ch9.pdf"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
