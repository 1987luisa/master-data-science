{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dsc/Downloads'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dsc\n"
     ]
    }
   ],
   "source": [
    "cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home\n"
     ]
    }
   ],
   "source": [
    "cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dsc/Repositories/master-data-science\r\n"
     ]
    }
   ],
   "source": [
    "!find -maxdepth 3 -type d -iname 'master*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dsc/Repositories/master-data-science\n"
     ]
    }
   ],
   "source": [
    "cd ./dsc/Repositories/master-data-science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mHist_cmd\u001b[0m/  \u001b[01;34mpractice\u001b[0m/  README.md\r\n"
     ]
    }
   ],
   "source": [
    "#Este archivo tiene cambios. deberían visualizarse en la web github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!git add .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting objects: 6, done.\n",
      "Delta compression using up to 4 threads.\n",
      "Compressing objects: 100% (6/6), done.\n",
      "Writing objects: 100% (6/6), 1.12 KiB | 286.00 KiB/s, done.\n",
      "Total 6 (delta 1), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
      "To https://github.com/hguadalupe/master-data-science.git\n",
      "   c8305bf..c5d59df  master -> master\n"
     ]
    }
   ],
   "source": [
    "!git push\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dsc/Repositories/master-data-science/practice\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../Data\r\n"
     ]
    }
   ],
   "source": [
    "!find ../../../ -maxdepth 2 -iname 'data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_route = '../../../Data/challenge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../Data/challenge/bookings.csv.bz2\r\n"
     ]
    }
   ],
   "source": [
    "!find '../../../Data/challenge' -maxdepth 4 -type f -iname 'book*' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bzip2: Can't open input file ../../../Data/challenge!ls/bookings.csv.bz2: No such file or directory.\r\n"
     ]
    }
   ],
   "source": [
    "!bzip2 -dk ../../../Data/challenge/bookings.csv.bz2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bookings.csv  bookings.csv.bz2\tsearches.csv.bz2\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../../Data/challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open '2' for reading: No such file or directory\r\n",
      "==> ../../../../Data/challenge/bookings.csv <==\r\n",
      "act_date           ^source^pos_ctry^pos_iata^pos_oid  ^rloc          ^cre_date           ^duration^distance^dep_port^dep_city^dep_ctry^arr_port^arr_city^arr_ctry^lst_port^lst_city^lst_ctry^brd_port^brd_city^brd_ctry^off_port^off_city^off_ctry^mkt_port^mkt_city^mkt_ctry^intl^route          ^carrier^bkg_class^cab_class^brd_time           ^off_time           ^pax^year^month^oid      \r\n",
      "2013-03-05 00:00:00^1A    ^DE      ^a68dd7ae953c8acfb187a1af2dcbe123^1a11ae49fcbf545fd2afc1a24d88d2b7^ea65900e72d71f4626378e2ebd298267^2013-02-22 00:00:00^1708^0^ZRH     ^ZRH     ^CH      ^LHR     ^LON     ^GB      ^ZRH     ^ZRH     ^CH      ^LHR     ^LON     ^GB      ^ZRH     ^ZRH     ^CH      ^LHRZRH  ^LONZRH  ^CHGB    ^1^LHRZRH         ^VI^T        ^Y        ^2013-03-07 08:50:00^2013-03-07 11:33:37^-1^2013^3^NULL     \r\n",
      "2013-03-26 00:00:00^1A    ^US      ^e612b9eeeee6f17f42d9b0d3b79e75ca^7437560d8f276d6d05eeb806d9e7edee^737295a86982c941f1c2da9a46a14043^2013-03-26 00:00:00^135270^0^SAL     ^SAL     ^SV      ^CLT     ^CLT     ^US      ^SAL     ^SAL     ^SV      ^SAL     ^SAL     ^SV      ^CLT     ^CLT     ^US      ^CLTSAL  ^CLTSAL  ^SVUS    ^1^SALATLCLT      ^NV^L        ^Y        ^2013-04-12 13:04:00^2013-04-12 22:05:40^1^2013^3^NULL     \r\n",
      "2013-03-26 00:00:00^1A    ^US      ^e612b9eeeee6f17f42d9b0d3b79e75ca^7437560d8f276d6d05eeb806d9e7edee^737295a86982c941f1c2da9a46a14043^2013-03-26 00:00:00^135270^0^SAL     ^SAL     ^SV      ^CLT     ^CLT     ^US      ^SAL     ^SAL     ^SV      ^CLT     ^CLT     ^US      ^SAL     ^SAL     ^SV      ^CLTSAL  ^CLTSAL  ^SVUS    ^1^CLTATLSAL      ^NV^U        ^Y        ^2013-07-15 07:00:00^2013-07-15 11:34:51^1^2013^3^NULL     \r\n",
      "2013-03-26 00:00:00^1A    ^AU      ^0f984b3bb6bd06661c95529bbd6193bc^36472c6dbaf7afec9136ac40364e2794^5ecf00fdcbcec761c43dc7285253d0c1^2013-03-26 00:00:00^30885^0^AKL     ^AKL     ^NZ      ^SVO     ^MOW     ^RU      ^AKL     ^AKL     ^NZ      ^AKL     ^AKL     ^NZ      ^SVO     ^MOW     ^RU      ^AKLSVO  ^AKLMOW  ^NZRU    ^1^AKLHKGSVO      ^XK^G        ^Y        ^2013-04-24 23:59:00^2013-04-25 16:06:31^1^2013^3^SYDA82546\r\n",
      "2013-03-26 00:00:00^1A    ^AU      ^0f984b3bb6bd06661c95529bbd6193bc^36472c6dbaf7afec9136ac40364e2794^5ecf00fdcbcec761c43dc7285253d0c1^2013-03-26 00:00:00^30885^0^AKL     ^AKL     ^NZ      ^SVO     ^MOW     ^RU      ^AKL     ^AKL     ^NZ      ^SVO     ^MOW     ^RU      ^AKL     ^AKL     ^NZ      ^AKLSVO  ^AKLMOW  ^NZRU    ^1^SVOHKGAKL      ^XK^G        ^Y        ^2013-05-14 20:15:00^2013-05-16 10:44:50^1^2013^3^SYDA82546\r\n",
      "2013-03-20 00:00:00^1V    ^US      ^0283592e45e392871f7e14b1e22a9aaf^2d0f8e7e1bb792625d2f34f221bc38f1^d54708298686de200f8270e7c637af5e^2013-03-20 00:00:00^5923^0^DEN     ^DEN     ^US      ^LGA     ^NYC     ^US      ^DEN     ^DEN     ^US      ^DEN     ^DEN     ^US      ^LGA     ^NYC     ^US      ^DENLGA  ^DENNYC  ^USUS    ^0^DENLGA         ^FK^W        ^Y        ^2013-04-07 10:23:00^2013-04-07 16:14:24^1^2013^3^NULL     \r\n",
      "2013-03-20 00:00:00^1V    ^US      ^0283592e45e392871f7e14b1e22a9aaf^2d0f8e7e1bb792625d2f34f221bc38f1^d54708298686de200f8270e7c637af5e^2013-03-20 00:00:00^5923^0^DEN     ^DEN     ^US      ^LGA     ^NYC     ^US      ^DEN     ^DEN     ^US      ^LGA     ^NYC     ^US      ^DEN     ^DEN     ^US      ^DENLGA  ^DENNYC  ^USUS    ^0^LGADEN         ^FK^K        ^Y        ^2013-04-11 11:15:00^2013-04-11 13:06:24^1^2013^3^NULL     \r\n",
      "2013-03-25 00:00:00^1V    ^JP      ^5af045902bd23cab579915611d99e1e0^5073861d8597467c33596bfe16f23c56^a37584d1485cb35991e4ff1a2ba92262^2013-03-25 00:00:00^8371^60^NRT     ^TYO     ^JP      ^SIN     ^SIN     ^SG      ^HND     ^TYO     ^JP      ^NRT     ^TYO     ^JP      ^SIN     ^SIN     ^SG      ^NRTSIN  ^SINTYO  ^JPSG    ^1^NRTSIN         ^XR^Q        ^Y        ^2013-04-14 11:05:00^2013-04-14 17:10:56^2^2013^3^NULL     \r\n",
      "2013-03-25 00:00:00^1V    ^JP      ^5af045902bd23cab579915611d99e1e0^5073861d8597467c33596bfe16f23c56^a37584d1485cb35991e4ff1a2ba92262^2013-03-25 00:00:00^8371^60^NRT     ^TYO     ^JP      ^SIN     ^SIN     ^SG      ^HND     ^TYO     ^JP      ^SIN     ^SIN     ^SG      ^PEN     ^PEN     ^MY      ^PENSIN  ^PENSIN  ^MYSG    ^1^SINPEN         ^WS^Y        ^Y        ^2013-04-16 15:45:00^2013-04-16 17:15:29^2^2013^3^NULL     \r\n"
     ]
    }
   ],
   "source": [
    "!head ../../../../Data/challenge/bookings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000011 ../../../../Data/challenge/bookings.csv\r\n"
     ]
    }
   ],
   "source": [
    "#Ejercicio 1. Recuento de líneas (versión linux)\n",
    "!wc -l ../../../../Data/challenge/bookings.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000011"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ejercicio 1. Recuento de líneas (versión python)\n",
    "route = '../../../../Data/challenge/bookings.csv'\n",
    "csv_opening = open(route)\n",
    "count = sum(1 for row in csv_opening)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0G ../../../../Data/challenge/bookings.csv\n",
      "['act_date           ^source^pos_ctry^pos_iata^pos_oid  ^rloc          ^cre_date           ^duration^distance^dep_port^dep_city^dep_ctry^arr_port^arr_city^arr_ctry^lst_port^lst_city^lst_ctry^brd_port^brd_city^brd_ctry^off_port^off_city^off_ctry^mkt_port^mkt_city^mkt_ctry^intl^route          ^carrier^bkg_class^cab_class^brd_time           ^off_time           ^pax^year^month^oid      ']\n",
      "  act_date           ^source^pos_ctry^pos_iata^pos_oid  ^rloc          ^cre_date           ^duration^distance^dep_port^dep_city^dep_ctry^arr_port^arr_city^arr_ctry^lst_port^lst_city^lst_ctry^brd_port^brd_city^brd_ctry^off_port^off_city^off_ctry^mkt_port^mkt_city^mkt_ctry^intl^route          ^carrier^bkg_class^cab_class^brd_time           ^off_time           ^pax^year^month^oid      \n",
      "0  2013-03-05 00:00:00^1A    ^DE      ^a68dd7ae95...                                                                                                                                                                                                                                                                                                                                             \n",
      "1  2013-03-26 00:00:00^1A    ^US      ^e612b9eeee...                                                                                                                                                                                                                                                                                                                                             \n",
      "2  2013-03-26 00:00:00^1A    ^US      ^e612b9eeee...                                                                                                                                                                                                                                                                                                                                             \n",
      "3  2013-03-26 00:00:00^1A    ^AU      ^0f984b3bb6...                                                                                                                                                                                                                                                                                                                                             \n",
      "4  2013-03-26 00:00:00^1A    ^AU      ^0f984b3bb6...                                                                                                                                                                                                                                                                                                                                             \n",
      "5  2013-03-20 00:00:00^1V    ^US      ^0283592e45...                                                                                                                                                                                                                                                                                                                                             \n",
      "6  2013-03-20 00:00:00^1V    ^US      ^0283592e45...                                                                                                                                                                                                                                                                                                                                             \n",
      "7  2013-03-25 00:00:00^1V    ^JP      ^5af045902b...                                                                                                                                                                                                                                                                                                                                             \n",
      "8  2013-03-25 00:00:00^1V    ^JP      ^5af045902b...                                                                                                                                                                                                                                                                                                                                             \n",
      "9  2013-03-25 00:00:00^1V    ^JP      ^5af045902b...                                                                                                                                                                                                                                                                                                                                             \n"
     ]
    }
   ],
   "source": [
    "#Ejercicio 1. Tantea el archivo con cuidado, para ver contenido y tamaño.\n",
    "pd_opening = pd.read_csv(route, sep='^',skip_blank_lines=True,nrows=10)\n",
    "!ls -sh ../../../../Data/challenge/bookings.csv\n",
    "print(list(pd_opening))\n",
    "print(pd_opening)\n",
    "#pd_opening = pd.read_csv('../../../../Data/challenge/bookings.csv', sep='^',skip_blank_lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tenemos un archivo de 4Gigas y 10 millones de filas. VAmos a tener que dividirlo en partes. \n",
    "#Podemos dividirlo en \"chunks\" de 100000 líneas con sqlalchemy, iterando sobre el CSV.\n",
    "#para ello tendremos que crear una bse de datos CSV.\n",
    "\n",
    "with open('bigcsv.csv', 'wb') as csvfile:\n",
    "    csvwriter =csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsc/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (7,8,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration is stopped\n"
     ]
    }
   ],
   "source": [
    "#Nofuncionó:\n",
    "def get_fromaction_data(fname,chunk_size=100000):\n",
    "    reader = pd.read_csv(fname,chunksize=chunk_size,sep='^',skip_blank_lines=True, iterator=True)\n",
    "    chunks =[]\n",
    "    loop =True\n",
    "    while loop:\n",
    "        try:\n",
    "            chunk =reader.get_chunk(chunk_size)\n",
    "            chunks.append(chunk)\n",
    "        except StopIteration:\n",
    "            loop =False\n",
    "            print(\"Iteration is stopped\")\n",
    "    \n",
    "    df_ac =pd.concat(chunks,ignore_index=True)\n",
    "    \n",
    "get_fromaction_data(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsc/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:1362: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  chunksize=chunksize, dtype=dtype)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_io.BufferedWriter' object has no attribute 'cursor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-550c58ac9666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'table'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'append'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, name, con, flavor, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         sql.to_sql(self, name, con, flavor=flavor, schema=schema,\n\u001b[1;32m   1361\u001b[0m                    \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m                    chunksize=chunksize, dtype=dtype)\n\u001b[0m\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, flavor, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[1;32m    469\u001b[0m     pandas_sql.to_sql(frame, name, if_exists=if_exists, index=index,\n\u001b[1;32m    470\u001b[0m                       \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m                       chunksize=chunksize, dtype=dtype)\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype)\u001b[0m\n\u001b[1;32m   1503\u001b[0m                             \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m                             dtype=dtype)\n\u001b[0;32m-> 1505\u001b[0;31m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fail'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Table '%s' already exists.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpd_sql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msql_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mhas_table\u001b[0;34m(self, name, schema)\u001b[0m\n\u001b[1;32m   1515\u001b[0m                  \"WHERE type='table' AND name=%s;\") % wld\n\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1517\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m             \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m             \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_io.BufferedWriter' object has no attribute 'cursor'"
     ]
    }
   ],
   "source": [
    "#Tenemos un archivo de 4Gigas y 10 millones de filas. VAmos a tener que dividirlo en partes. \n",
    "#Podemos dividirlo en \"chunks\" de 100000 líneas con sqlalchemy, iterando sobre el CSV.\n",
    "chunksize = 100000\n",
    "i = 0\n",
    "j = 1\n",
    "for df1 in pd.read_csv(route,chunksize=chunksize,sep='^',skip_blank_lines=True, iterator=True):\n",
    "    df1.index += j\n",
    "    i+=1\n",
    "    df1.to_sql('table', csvfile, if_exists='append')\n",
    "    j = df1.index[-1] + 1\n",
    "\n",
    "#CAUTION df_top10= pd.read_csv(route, sep='^',skip_blank_lines=True).loc[:,'arr_port'].sum()\n",
    "\n",
    "#df.columns.str.replace('\\s+','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0G ../../../../Data/challenge/bookings.csv\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
